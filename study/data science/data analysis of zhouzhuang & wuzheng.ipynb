{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall echarts-cities-pypkg\n",
    "# !pip uninstall echarts-countries-pypkg\n",
    "# !pip uninstall echarts-china-provinces-pypkg\n",
    "# !pip uninstall echarts-china-cities-pypkg\n",
    "# !pip uninstall echarts-china-counties-pypkg\n",
    "# !pip uninstall echarts-china-misc-pypkg\n",
    "\n",
    "!pip install echarts-cities-pypkg\n",
    "!pip install echarts-countries-pypkg\n",
    "!pip install echarts-china-provinces-pypkg\n",
    "!pip install echarts-china-cities-pypkg\n",
    "!pip install echarts-china-counties-pypkg\n",
    "!pip install echarts-china-misc-pypkg\n",
    "!pip install jupyter_echarts_pypkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T11:02:08.422989Z",
     "start_time": "2019-04-03T11:02:08.117894Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "a = \"zz&wz_data.xlsx\" # 乌镇&周庄数据原始数据\n",
    "b = \"zz&wz.xlsx\" # 乌镇&周庄数据聚合数据\n",
    "c = \"china_coordinates.csv\" # 经纬度数据\n",
    "e = \"total.csv\"  # 评论数据\n",
    "f = \"provinces_gdp.csv\"\n",
    "g = \"zz&wz_spot_coordinate.xlsx\"\n",
    "# 添加经纬度\n",
    "ll= pd.read_csv(c,header=None,names=['code','name','lon','lat'])\n",
    "gdp = pd.read_csv(f,encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T11:02:10.251037Z",
     "start_time": "2019-04-03T11:02:10.239193Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据处理模块\n",
    "def gen_data(sheet, flag=None):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    # read data\n",
    "    spot_coordinate = pd.read_excel(g,sheet_name='spot_coordinates')\n",
    "    spots = pd.read_excel(g,sheet_name=sheet).replace(\"——\", \"\")\n",
    "    # gen spot coordinate mapping\n",
    "    key = spot_coordinate.spot.tolist()\n",
    "    lon = spot_coordinate.lon.tolist()\n",
    "    lat = spot_coordinate.lat.tolist()\n",
    "    spot_maping = {k:[lon[i],lat[i]] for i,k in enumerate(key)}\n",
    "    # gen sankey data\n",
    "    data = []\n",
    "    cols = spots.columns.tolist()\n",
    "    flag =(0,len(cols)-1) if not flag else flag\n",
    "    # for i in range(len(cols)-4):\n",
    "    for i in range(flag[0],flag[1]):\n",
    "        print(cols[i],cols[i+1])\n",
    "        tmp = spots[(spots[cols[i]].isin(spot_maping))& (spots[cols[i+1]].isin(spot_maping))][[cols[i],cols[i+1]]]\n",
    "        if i%2 == 0:\n",
    "            top_10 = tmp.groupby(cols[i]).count().sort_values(by=cols[i+1],ascending=False).head(10).index.tolist()\n",
    "            tmp_top10 = tmp[tmp[cols[i]].isin(top_10)]\n",
    "            for m, group in tmp_top10.groupby(cols[i]):\n",
    "                group['freq'] = group.groupby(cols[i+1])[cols[i+1]].transform('count')\n",
    "                data.extend(group.sort_values(by='freq',ascending=False).drop_duplicates().head(10).values.tolist())\n",
    "        else:\n",
    "            top_10 = tmp.groupby(cols[i+1]).count().sort_values(by=cols[i],ascending=False).head(10).index.tolist()\n",
    "            tmp_top10 = tmp[tmp[cols[i+1]].isin(top_10)]\n",
    "            for m, group in tmp_top10.groupby(cols[i+1]):\n",
    "                group['freq'] = group.groupby(cols[i])[cols[i]].transform('count')\n",
    "                data.extend(group.sort_values(by='freq',ascending=False).drop_duplicates().head(10).values.tolist())\n",
    "    return (data,spot_maping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T11:02:22.574484Z",
     "start_time": "2019-04-03T11:02:21.855403Z"
    }
   },
   "outputs": [],
   "source": [
    "# 绘制桑基图模块\n",
    "from pyecharts import Sankey\n",
    "from pyecharts import configure\n",
    "configure(output_image='png')\n",
    "\n",
    "# worker of make sankey\n",
    "def gen_sankey(sheet,name,flag=None):\n",
    "    # gen data\n",
    "    data = gen_data(sheet, flag)[0]\n",
    "    links = [{\"source\": i[0],\"target\": i[1],\"value\": i[2]} for i in data]\n",
    "    tmp = set([i[0] for i in data] + [i[1] for i in data])\n",
    "    nodes = [{'name':i} for i in tmp]\n",
    "    # gen sankey map\n",
    "    sankey = Sankey(\"\", width=1200, height=600)\n",
    "    print(nodes,links)\n",
    "    sankey.add(\n",
    "        name,\n",
    "        nodes=nodes,\n",
    "        links=links,\n",
    "        line_opacity=0.2,\n",
    "        line_curve=0.5,\n",
    "        line_color=\"red\",\n",
    "        is_label_show=True,\n",
    "        label_pos=\"right\"\n",
    "    )\n",
    "    sankey.render(path=f\"{name}.html\")\n",
    "    return sankey\n",
    "\n",
    "# gen_sankey('wz',\"乌镇流入Top10\",flag=(2,3))\n",
    "# gen_sankey('wz',\"乌镇流出Top10\",flag=(3,4))\n",
    "gen_sankey('zz',\"周庄流入Top10\",flag=(2,3))\n",
    "# gen_sankey('zz',\"周庄流出Top10\",flag=(3,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T11:02:27.628021Z",
     "start_time": "2019-04-03T11:02:26.871661Z"
    }
   },
   "outputs": [],
   "source": [
    "# 绘制 流量迁徙图模块\n",
    "from pyecharts import GeoLines, Style\n",
    "\n",
    "# worker of make geolines\n",
    "def gen_geolines(sheet,name,flag=None):\n",
    "    # gen data\n",
    "    data,spot_maping = gen_data(sheet, flag)\n",
    "    # gen geolines map\n",
    "    style = Style(\n",
    "        title_top=\"#fff\",\n",
    "        title_pos = \"center\",\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        background_color=\"#404a59\"\n",
    "    )\n",
    "    style_geo = style.add(\n",
    "        is_label_show=True,\n",
    "        line_curve=0.2,\n",
    "        line_opacity=0.6,\n",
    "        legend_text_color=\"#eee\",\n",
    "        legend_pos=\"right\",\n",
    "        geo_effect_symbol=\"plane\",  #  'circle', 'rect', 'roundRect', 'triangle', 'diamond', 'pin', 'arrow', 'plane' \n",
    "        geo_effect_symbolsize=15,\n",
    "        label_color=['#a6c84c', '#ffa022', '#46bee9'],\n",
    "        label_pos=\"right\",\n",
    "        label_formatter=\"{b}\",\n",
    "        label_text_color=\"#eee\",\n",
    "    )\n",
    "    geolines = GeoLines(name, **style.init_style)\n",
    "    geolines.add(\"\", data, geo_cities_coords=spot_maping, tooltip_formatter=\"{b}:{c}\",**style_geo)\n",
    "    geolines.render(path=f\"{name}.html\")\n",
    "    return geolines\n",
    "\n",
    "gen_geolines('wz',\"乌镇景点迁徙图\",flag=(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import GeoLines, Style\n",
    "\n",
    "data_guangzhou = [\n",
    "    [\"广州\", \"上海\", 10],\n",
    "    [\"广州\", \"北京\", 20],\n",
    "    [\"广州\", \"南京\", 30],\n",
    "    [\"广州\", \"重庆\", 40],\n",
    "    [\"广州\", \"兰州\", 50],\n",
    "    [\"广州\", \"杭州\", 60],\n",
    "]\n",
    "lines = GeoLines(\"GeoLines 示例\", **style.init_style)\n",
    "lines.add(\n",
    "    \"从广州出发\", data_guangzhou, tooltip_formatter=\"{a} : {c}\", **style_geo\n",
    ")\n",
    "lines.render()\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理city表\n",
    "zz = pd.read_excel(a,sheet_name='zz_city')\n",
    "wz = pd.read_excel(a,sheet_name='wz_city')\n",
    "zz.rename(columns={'count': 'zz_count', 'pct': 'zz_pct'}, inplace = True)\n",
    "wz.rename(columns={'count': 'wz_count', 'pct': 'wz_pct'}, inplace = True)\n",
    "city = ll[['name','lon','lat']]\n",
    "city.rename(columns={'name': 'city'}, inplace = True)\n",
    "\n",
    "df = pd.merge(zz,wz,how='outer').fillna(value={'zz_count':0,'zz_pct':0.0})\n",
    "df.city.replace({'哈密地区':'哈密市','海西蒙古族藏族自治州直辖':'海西蒙古族藏族自治州','吐鲁番地区':'吐鲁番市',\n",
    "                 '日喀则地区':'日喀则市','林芝地区':'林芝市','山南地区':'山南市','昌都地区':'昌都市'},inplace=True)\n",
    "df.zz_count=df.zz_count.astype(int)\n",
    "df=pd.merge(df,city,how='left')\n",
    "df.info()\n",
    "\n",
    "with pd.ExcelWriter(b, engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name='city',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理省份表\n",
    "zz_prov = pd.read_excel(a,sheet_name='zz_prov')\n",
    "wz_prov = pd.read_excel(a,sheet_name='wz_prov')\n",
    "school = pd.read_excel(a,sheet_name='school_prov')\n",
    "population = pd.read_excel(a,sheet_name='population_prov')\n",
    "nets = pd.read_excel(a,sheet_name='nets_pct_prov')\n",
    "cars = pd.read_excel(a,sheet_name='cars_prov')\n",
    "\n",
    "prov = ll[['name','lon','lat']]\n",
    "prov.rename(columns={'name': 'prov'}, inplace = True)\n",
    "\n",
    "zz_prov['prov'].replace('新疆维吾尔自治区', '新疆维吾尔族自治区', inplace=True) \n",
    "wz_prov['prov'].replace('新疆维吾尔自治区', '新疆维吾尔族自治区', inplace=True) \n",
    "population['prov'].replace({'新疆维吾尔自治区':'新疆维吾尔族自治区','香港':'香港特别行政区','澳门':'澳门特别行政区'}, inplace=True)\n",
    "population['population']=population['population'].map(lambda x:x.replace('万',''))\n",
    "nets['prov'].replace('新疆维吾尔自治区', '新疆维吾尔族自治区', inplace=True) \n",
    "cars['prov'].replace('新疆维吾尔自治区', '新疆维吾尔族自治区', inplace=True) \n",
    "prov['prov'].replace('新疆维吾尔自治区', '新疆维吾尔族自治区', inplace=True) \n",
    "\n",
    "zz_prov.rename(columns={'count': 'zz_people_cnt', 'pct': 'zz_people_pct'}, inplace = True)\n",
    "wz_prov.rename(columns={'count': 'wz_people_cnt', 'pct': 'wz_people_pct'}, inplace = True)\n",
    "school.rename(columns={'benke': 'bk_school_cnt', 'zhuanke': 'zk_school_cnt','total':'school_cnt'}, inplace = True)\n",
    "nets.rename(columns={'pct': 'nets_pct'}, inplace = True)\n",
    "\n",
    "df = pd.merge(zz_prov,wz_prov,how='outer')\n",
    "df = pd.merge(df,school,how='outer')\n",
    "df = pd.merge(df,population,how='outer')\n",
    "df = pd.merge(df,nets,how='outer')\n",
    "df = pd.merge(df,cars,how='outer').fillna(0)\n",
    "df = pd.merge(df,prov,how='left')\n",
    "df.info()\n",
    "df\n",
    "with pd.ExcelWriter(b, mode='a', engine='openpyxl') as writer:\n",
    "    df.to_excel(writer, sheet_name='prov',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理词云\n",
    "df = pd.read_csv(e).fillna('')\n",
    "df.info()\n",
    "df.replace('用户未点评，系统默认好评。', '',inplace=True)\n",
    "df['content']=df.content.map(lambda x:x.replace('&#x20', '').replace('取票','').replace('方便','').replace('&#x0A;',''))\n",
    "# df[df.content== '&#x20']\n",
    "# df[df.star.isnull()]\n",
    "# print(df[df.spot=='乌镇'].count())\n",
    "# df[df.spot=='周庄'].count()\n",
    "wz_str = ''.join(df[df.spot=='乌镇'].content.tolist())\n",
    "zz_str = ''.join(df[df.spot=='周庄'].content.tolist())\n",
    "# wz_str\n",
    "df[df.spot=='乌镇'].star.mean()\n",
    "# df[df.spot=='周庄'].star.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import webbrowser\n",
    "from folium.plugins import HeatMap\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import jieba\n",
    "# sns.boxplot(data=df[df.spot=='乌镇'])\n",
    "# plt.show()\n",
    "\n",
    "df[df.spot=='周庄'].star.mean()\n",
    "# df[df.spot=='乌镇'].star.mean()\n",
    "\n",
    "star_z = df[df.spot=='周庄'].groupby('star').count()\n",
    "star_w = df[df.spot=='乌镇'].groupby('star').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'score': star_z.index, 'count': star_z.spot, 'name':'zhouzhuang'})\n",
    "df2 = pd.DataFrame({'score': star_w.index, 'count': star_w.spot, 'name':'wuzhen'})\n",
    "df3 = df1.append(df2)\n",
    "sns.lineplot(x='score', y='count', data=df3, hue='name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stop_words\n",
    "from stop_words import get_stop_words  ## no chinese stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import jieba,io\n",
    "stop_words = [line.strip().decode('utf-8') for line in io.open('stop_words.txt').readlines()]+['我们','特别','不错','非常','真的','比较']\n",
    "# token_pattern = ''\n",
    "# tfidf_vec = TfidfVectorizer(stop_words=stop_words, token_pattern=token_pattern)\n",
    "tfidf_vec = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "\n",
    "\n",
    "# 不重复的词\n",
    "# tfidf_vec.get_feature_names()\n",
    "# 每个单词的ID\n",
    "\n",
    "# 每个单词的tfidf值\n",
    "tfidf_vec = TfidfVectorizer(stop_words=stop_words)\n",
    "zz_comment = df[df.spot=='周庄'].content.tolist()[:1000]\n",
    "zz_tmp = [\" \".join(jieba.cut(i)) for i in zz_comment]\n",
    "zz_tfidf_matrix = tfidf_vec.fit_transform(zz_tmp)\n",
    "zz_tfidfs = zz_tfidf_matrix.toarray()\n",
    "\n",
    "ids = tfidf_vec.vocabulary_\n",
    "words = {v: k for k, v in ids.items()}\n",
    "\n",
    "zz_keys_words = \" \".join([words.get(list(i).index(max(i))) for i in zz_tfidfs])\n",
    "zz_wordcloud = WordCloud(background_color=\"white\",width=1000, height=860, margin=2,\n",
    "                      font_path=\"simsun.ttf\").generate(zz_keys_words)\n",
    "plt.imshow(zz_wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "# zz_wordcloud.to_file('zz_wordcloud.png')\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(stop_words=stop_words)\n",
    "wz_comment = df[df.spot=='乌镇'].content.tolist()[:1000]\n",
    "wz_tmp = [\" \".join(jieba.cut(i)) for i in wz_comment]\n",
    "wz_tfidf_matrix = tfidf_vec.fit_transform(wz_tmp)\n",
    "\n",
    "ids = tfidf_vec.vocabulary_\n",
    "words = {v: k for k, v in ids.items()}\n",
    "\n",
    "wz_tfidfs = wz_tfidf_matrix.toarray()\n",
    "wz_keys_words = \" \".join([words.get(list(i).index(max(i))) for i in wz_tfidfs])\n",
    "wz_wordcloud = WordCloud(background_color=\"white\",width=1000, height=860, margin=2,\n",
    "                      font_path=\"simsun.ttf\").generate(wz_keys_words)\n",
    "plt.imshow(wz_wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "wz_wordcloud.to_file('wz_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import jieba\n",
    "\n",
    "# content_str = open('wc.csv').read()\n",
    "\n",
    "wz_str_tmp = jieba.cut(wz_str)\n",
    "wz_jieba = \" \".join(wz_str_tmp)\n",
    "zz_str_tmp = jieba.cut(zz_str)\n",
    "zz_jieba = \" \".join(zz_str_tmp)\n",
    "\n",
    "wz_mask = np.array(Image.open(\"乌镇.jpg\"))\n",
    "zz_mask = np.array(Image.open(\"周庄.jpg\"))\n",
    "\n",
    "\n",
    "# wz_wordcloud = WordCloud(background_color=\"white\",width=1000, height=860, margin=2,\n",
    "#                       font_path=\"simsun.ttf\",mask=wz_mask).generate(wz_str)\n",
    "# zz_wordcloud = WordCloud(background_color=\"white\",width=1000, height=860, margin=2,\n",
    "#                       font_path=\"simsun.ttf\",mask=zz_mask).generate(zz_str)\n",
    "wz_wordcloud = WordCloud(background_color=\"white\",width=1000, height=860, margin=2,\n",
    "                      font_path=\"simsun.ttf\").generate(wz_str)\n",
    "zz_wordcloud = WordCloud(background_color=\"white\",width=1000, height=860, margin=2,\n",
    "                      font_path=\"simsun.ttf\").generate(zz_str)\n",
    "# width,height,margin可以设置图片属性\n",
    "\n",
    "# generate 可以对全部文本进行自动分词,但是他对中文支持不好\n",
    "# 可以通过font_path参数来设置字体集\n",
    "#background_color参数为设置背景颜色,默认颜色为黑色\n",
    "\n",
    "\n",
    "plt.imshow(wz_wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(zz_wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# 保存图片,但是在第三模块的例子中 图片大小将会按照 mask 保存\n",
    "wz_wordcloud.to_file('wz_wordcloud.png')\n",
    "zz_wordcloud.to_file('zz_wordcloud.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制热力图\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import webbrowser\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "city = pd.read_excel(b,sheet_name='city')\n",
    "prov = pd.read_excel(b,sheet_name='prov')\n",
    "prov['population']=prov.population.astype(float)\n",
    "\n",
    "# lat = np.array(city[\"lat\"])\n",
    "# lon = np.array(city[\"lon\"])\n",
    "# zz = np.array(city[\"zz_count\"],dtype=float)\n",
    "# wz = np.array(city[\"wz_count\"],dtype=float)\n",
    "# data1 = [[lat[i],lon[i],pop[i]] for i in range(num)]    #将数据制作成[lats,lons,weights]的形式\n",
    "\n",
    "data_zz = city[[\"lat\",\"lon\",\"zz_count\"]].values.tolist()\n",
    "map_osm = folium.Map(location=[35,110],zoom_start=5)    #绘制Map，开始缩放程度是5倍\n",
    "HeatMap(data_zz).add_to(map_osm)  # 将热力图添加到前面建立的map里\n",
    "file_path = \"zz_city.html\"\n",
    "map_osm.save(file_path)     # 保存为html文件\n",
    "\n",
    "data_wz = city[[\"lat\",\"lon\",\"wz_count\"]].values.tolist()\n",
    "map_osm = folium.Map(location=[35,110],zoom_start=5)    #绘制Map，开始缩放程度是5倍\n",
    "HeatMap(data_wz).add_to(map_osm)  # 将热力图添加到前面建立的map里\n",
    "file_path = \"wz_city.html\"\n",
    "map_osm.save(file_path)     # 保存为html文件\n",
    "\n",
    "data_zz_prov = prov[[\"lat\",\"lon\",\"zz_people_cnt\"]].values.tolist()\n",
    "map_osm = folium.Map(location=[35,110],zoom_start=5)    #绘制Map，开始缩放程度是5倍\n",
    "HeatMap(data_zz_prov).add_to(map_osm)  # 将热力图添加到前面建立的map里\n",
    "file_path = \"zz_prov.html\"\n",
    "map_osm.save(file_path) \n",
    "\n",
    "data_wz_prov = prov[[\"lat\",\"lon\",\"wz_people_cnt\"]].values.tolist()\n",
    "map_osm = folium.Map(location=[35,110],zoom_start=5)    #绘制Map，开始缩放程度是5倍\n",
    "HeatMap(data_wz_prov).add_to(map_osm)  # 将热力图添加到前面建立的map里\n",
    "file_path = \"wz_prov.html\"\n",
    "map_osm.save(file_path) \n",
    "\n",
    "# webbrowser.open(file_path)  # 默认浏览器打开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov.info()\n",
    "prov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov.sort_values(by=['population'],ascending=False,inplace=True)\n",
    "prov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdp.rename(columns={'地区':'prov','2016年':'gdp'},inplace=True)\n",
    "gdp['prov'].replace('新疆维吾尔自治区', '新疆维吾尔族自治区', inplace=True) \n",
    "prov_gdp = pd.merge(prov,gdp[['prov','gdp']], how='left').fillna(0)\n",
    "prov_gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 使用Seaborn画折线图\n",
    "prov_ = prov[~prov['prov'].isin(['浙江省','上海市','江苏省'])]\n",
    "name =[\"population\",\"bk_school_cnt\",\"zk_school_cnt\",\"school_cnt\",\"nets_pct\",\"cars\"]\n",
    "for i in name:\n",
    "    df1 = pd.DataFrame({i: prov_[i], 'people_cnt': prov_.zz_people_cnt, 'name':'zhouzhuang'})\n",
    "    df2 = pd.DataFrame({i: prov_[i], 'people_cnt': prov_.wz_people_cnt, 'name':'wuzhen'})\n",
    "    df3 = df1.append(df2)\n",
    "    sns.lineplot(x=i, y=\"people_cnt\", data=df3, hue='name')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov[~prov['prov'].isin(['浙江省','上海市','江苏省'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name =[\"population\",\"bk_school_cnt\",\"zk_school_cnt\",\"school_cnt\",\"nets_pct\",\"cars\"]\n",
    "name =[\"zz_people_cnt\",\"wz_people_cnt\",\"population\",\"bk_school_cnt\",\"zk_school_cnt\",\"school_cnt\",\"nets_pct\",\"cars\",'gdp']\n",
    "sns.pairplot(prov_gdp[~prov_gdp['prov'].isin(['浙江省','上海市','江苏省','香港特别行政区','澳门特别行政区','台湾省'])][name])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# people = min_max_scaler.fit_transform([prov.zz_people_cnt, prov.wz_people_cnt])\n",
    "# wz_peoples = min_max_scaler.fit_transform(prov[['zz_people_cnt','wz_people_cnt']]).T\n",
    "# print(wz_peoples)\n",
    "with sns.axes_style(\"white\"):\n",
    "#     sns.jointplot(wz_peoples[0], wz_peoples[1], kind=\"scatter\", color=\"b\")\n",
    "    sns.jointplot(prov_.zz_people_cnt, prov_.wz_people_cnt, kind=\"reg\", color=\"b\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x='zz_people_cnt', y='wz_people_cnt', data=prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prov.info()\n",
    "# prov\n",
    "# Seaborn可视化\n",
    "\n",
    "sns.set(context=\"notebook\")\n",
    "# 设置风格，seaborn有5种基本风格，context表示环境\n",
    "\n",
    "x = prov['wz_people_cnt'].astype(int).tolist()\n",
    "sns.distplot(x, bins = 15, kde=True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " prov.sort_values(by=['zz_people_cnt'], ascending=[True],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"total_bill\", y=\"day\", hue=\"time\", data=tips)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stop_words = ['and', 'is', 'one', 'the', 'this']\n",
    "# token_pattern = ''\n",
    "# tfidf_vec = TfidfVectorizer(stop_words=stop_words, token_pattern=token_pattern)\n",
    "tfidf_vec = TfidfVectorizer(stop_words=stop_words)\n",
    "documents = [\n",
    "    'this is the bayes document',\n",
    "    'this is the second second document',\n",
    "    'and the third one',\n",
    "    'is this the document'\n",
    "]\n",
    "tfidf_matrix = tfidf_vec.fit_transform(documents)\n",
    "# 不重复的词\n",
    "tfidf_vec.get_feature_names()\n",
    "# 每个单词的ID\n",
    "tfidf_vec.vocabulary_\n",
    "# 每个单词的tfidf值\n",
    "# tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyecharts pyecharts_snapshot\n",
    "from pyecharts import GeoLines, Style\n",
    "\n",
    "style = Style(\n",
    "    title_top=\"#fff\",\n",
    "    title_pos = \"center\",\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    background_color=\"#404a59\"\n",
    ")\n",
    "\n",
    "data_guangzhou = [\n",
    "    [\"北京\", \"上海\"],\n",
    "    [\"北京\", \"北京\"],\n",
    "    [\"广州\", \"南京\"],\n",
    "    [\"广州\", \"重庆\"],\n",
    "    [\"北京\", \"兰州\"],\n",
    "    [\"广州\", \"杭州\"]\n",
    "]\n",
    "\n",
    "style_geo = style.add(\n",
    "    is_label_show=True,\n",
    "    line_curve=0.2,\n",
    "    line_opacity=0.6,\n",
    "    legend_text_color=\"#eee\",\n",
    "    legend_pos=\"right\",\n",
    "    geo_effect_symbol=\"plane\",\n",
    "    geo_effect_symbolsize=15,\n",
    "    label_color=['#a6c84c', '#ffa022', '#46bee9'],\n",
    "    label_pos=\"right\",\n",
    "    label_formatter=\"{b}\",\n",
    "    label_text_color=\"#eee\",\n",
    ")\n",
    "geolines = GeoLines(\"GeoLines 示例\", **style.init_style)\n",
    "geolines.add(\"从广州出发\", data_guangzhou, **style_geo)\n",
    "geolines.render()\n",
    "geolines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyecharts import GeoLines, Style\n",
    " \n",
    "#这里先经度后纬度，定义各个点坐标\n",
    "geo_cities_coords={'三林': [121.5123244, 31.143310800000002],\n",
    "                   '三林东': [121.5232337, 31.14652508],\n",
    "                   '三门路': [121.50799520000001, 31.31309147],\n",
    "                   '上南路': [121.5064128, 31.14911246],\n",
    "                   '上大路': [121.40917900000001, 31.31352358],\n",
    "                   '上海体育场': [121.44371310000001, 31.18552163],\n",
    "                   '上海体育馆': [121.4370549, 31.18272248],\n",
    "                   '上海儿童医学中心': [121.5239264, 31.20405048]}  \n",
    " \n",
    " \n",
    "style = Style(\n",
    "    title_top=\"#fff\",\n",
    "    title_pos = \"center\",\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    background_color=\"#404a59\"\n",
    ")\n",
    " \n",
    "dataline=[[\"三林\",\"上海儿童医学中心\"],\n",
    "         [\"三林东\",\"上海体育馆\"],\n",
    "         [\"三门路\",\"上海体育场\"],\n",
    "         [\"上南路\",\"上大路\"]]\n",
    " \n",
    "geolines = GeoLines(\"GeoLines 示例\", **style.init_style)\n",
    "geolines.add(\"\", dataline, maptype = '上海',geo_cities_coords=geo_cities_coords)\n",
    "geolines.render()\n",
    "geolines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import Geo\n",
    "\n",
    "data = [\n",
    "    (\"海门\", 9),(\"鄂尔多斯\", 12),(\"招远\", 12),(\"舟山\", 12),(\"齐齐哈尔\", 14),(\"盐城\", 15),\n",
    "    (\"赤峰\", 16),(\"青岛\", 18),(\"乳山\", 18),(\"金昌\", 19),(\"泉州\", 21),(\"莱西\", 21),\n",
    "    (\"日照\", 21),(\"胶南\", 22),(\"南通\", 23),(\"拉萨\", 24),(\"云浮\", 24),(\"梅州\", 25),\n",
    "    (\"文登\", 25),(\"上海\", 25),(\"攀枝花\", 25),(\"威海\", 25),(\"承德\", 25),(\"厦门\", 26),\n",
    "    (\"汕尾\", 26),(\"潮州\", 26),(\"丹东\", 27),(\"太仓\", 27),(\"曲靖\", 27),(\"烟台\", 28),\n",
    "    (\"福州\", 29),(\"瓦房店\", 30),(\"即墨\", 30),(\"抚顺\", 31),(\"玉溪\", 31),(\"张家口\", 31),\n",
    "    (\"阳泉\", 31),(\"莱州\", 32),(\"湖州\", 32),(\"汕头\", 32),(\"昆山\", 33),(\"宁波\", 33),\n",
    "    (\"湛江\", 33),(\"揭阳\", 34),(\"荣成\", 34),(\"连云港\", 35),(\"葫芦岛\", 35),(\"常熟\", 36),\n",
    "    (\"东莞\", 36),(\"河源\", 36),(\"淮安\", 36),(\"泰州\", 36),(\"南宁\", 37),(\"营口\", 37),\n",
    "    (\"惠州\", 37),(\"江阴\", 37),(\"蓬莱\", 37),(\"韶关\", 38),(\"嘉峪关\", 38),(\"广州\", 38),\n",
    "    (\"延安\", 38),(\"太原\", 39),(\"清远\", 39),(\"中山\", 39),(\"昆明\", 39),(\"寿光\", 40),\n",
    "    (\"盘锦\", 40),(\"长治\", 41),(\"深圳\", 41),(\"珠海\", 42),(\"宿迁\", 43),(\"咸阳\", 43),\n",
    "    (\"铜川\", 44),(\"平度\", 44),(\"佛山\", 44),(\"海口\", 44),(\"江门\", 45),(\"章丘\", 45),\n",
    "    (\"肇庆\", 46),(\"大连\", 47),(\"临汾\", 47),(\"吴江\", 47),(\"石嘴山\", 49),(\"沈阳\", 50),\n",
    "    (\"苏州\", 50),(\"茂名\", 50),(\"嘉兴\", 51),(\"长春\", 51),(\"胶州\", 52),(\"银川\", 52),\n",
    "    (\"张家港\", 52),(\"三门峡\", 53),(\"锦州\", 54),(\"南昌\", 54),(\"柳州\", 54),(\"三亚\", 54),\n",
    "    (\"自贡\", 56),(\"吉林\", 56),(\"阳江\", 57),(\"泸州\", 57),(\"西宁\", 57),(\"宜宾\", 58),\n",
    "    (\"呼和浩特\", 58),(\"成都\", 58),(\"大同\", 58),(\"镇江\", 59),(\"桂林\", 59),(\"张家界\", 59),\n",
    "    (\"宜兴\", 59),(\"北海\", 60),(\"西安\", 61),(\"金坛\", 62),(\"东营\", 62),(\"牡丹江\", 63),\n",
    "    (\"遵义\", 63),(\"绍兴\", 63),(\"扬州\", 64),(\"常州\", 64),(\"潍坊\", 65),(\"重庆\", 66),\n",
    "    (\"台州\", 67),(\"南京\", 67),(\"滨州\", 70),(\"贵阳\", 71),(\"无锡\", 71),(\"本溪\", 71),\n",
    "    (\"克拉玛依\", 72),(\"渭南\", 72),(\"马鞍山\", 72),(\"宝鸡\", 72),(\"焦作\", 75),(\"句容\", 75),\n",
    "    (\"北京\", 79),(\"徐州\", 79),(\"衡水\", 80),(\"包头\", 80),(\"绵阳\", 80),(\"乌鲁木齐\", 84),\n",
    "    (\"枣庄\", 84),(\"杭州\", 84),(\"淄博\", 85),(\"鞍山\", 86),(\"溧阳\", 86),(\"库尔勒\", 86),\n",
    "    (\"安阳\", 90),(\"开封\", 90),(\"济南\", 92),(\"德阳\", 93),(\"温州\", 95),(\"九江\", 96),\n",
    "    (\"邯郸\", 98),(\"临安\", 99),(\"兰州\", 99),(\"沧州\", 100),(\"临沂\", 103),(\"南充\", 104),\n",
    "    (\"天津\", 105),(\"富阳\", 106),(\"泰安\", 112),(\"诸暨\", 112),(\"郑州\", 113),(\"哈尔滨\", 114),\n",
    "    (\"聊城\", 116),(\"芜湖\", 117),(\"唐山\", 119),(\"平顶山\", 119),(\"邢台\", 119),(\"德州\", 120),\n",
    "    (\"济宁\", 120),(\"荆州\", 127),(\"宜昌\", 130),(\"义乌\", 132),(\"丽水\", 133),(\"洛阳\", 134),\n",
    "    (\"秦皇岛\", 136),(\"株洲\", 143),(\"石家庄\", 147),(\"莱芜\", 148),(\"常德\", 152),(\"保定\", 153),\n",
    "    (\"湘潭\", 154),(\"金华\", 157),(\"岳阳\", 169),(\"长沙\", 175),(\"衢州\", 177),(\"廊坊\", 193),\n",
    "    (\"菏泽\", 194),(\"合肥\", 229),(\"武汉\", 273),(\"大庆\", 279)]\n",
    "\n",
    "geo = Geo(\"地理坐标系示例\",\n",
    "            title_color=\"#fff\",\n",
    "            title_pos=\"center\",\n",
    "            width=1200,\n",
    "            height=600,\n",
    "            background_color=\"#404a59\",\n",
    "          )\n",
    "\n",
    "attr,value = geo.cast(data) # 将内容拆成k,v两个列表\n",
    "\n",
    "geo.add(\"\",attr,value,\n",
    "        type=\"scatter\",\n",
    "        maptype='china', # 地图类型。 从 v0.3.2+ 起，地图已经变为扩展包，支持全国省份，全国城市，全国区县，全球国家等地图\n",
    "        coordinate_region='中国', # TODO 城市坐标所属国家\n",
    "        symbol_size=12, # 点的大小\n",
    "        border_color=\"#111\",\n",
    "        geo_normal_color=\"#323c48\",\n",
    "        geo_emphasis_color=\"#2a333d\",\n",
    "        geo_cities_coords=None, # TODO 支持自定义经纬度，数据类型dict {\"城市\"：[122,200]}\n",
    "        is_roam=True, # 缩放，拖拽\n",
    "        visual_range=[0, 200],\n",
    "        visual_text_color=\"#fff\",\n",
    "        is_visualmap=True,\n",
    "        )\n",
    "geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "from pyecharts import Sankey\n",
    "\n",
    "with codecs.open(\"energy.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    j = json.load(f)\n",
    "\n",
    "sankey = Sankey(\"桑基图示例\", width=1200, height=600)\n",
    "sankey.add(\n",
    "    \"sankey\",\n",
    "    nodes=j[\"nodes\"],\n",
    "    links=j[\"links\"],\n",
    "    line_opacity=0.2,\n",
    "    line_curve=0.5,\n",
    "    line_color=\"source\",\n",
    "    is_label_show=True,\n",
    "    label_pos=\"right\",\n",
    ")\n",
    "sankey.render()\n",
    "sankey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5200* 11000/6200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6778589"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5523457+54385107+64687405+62809247-180626627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "UserAgent.chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-93ae88d2e7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "eval(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577917060"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "288958530*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15200889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28037 + 12721 + 110054 + 20213 + 3230 + 50 + 44837 + 231810 + 169117 + 274350 + 240045 + 656800 + 151671 + 320222 + 269562 + 194146 + 253087 + 212484 + 285947 + 468003 + 282899 + 167842 + 307913 + 1007046 + 249377 + 220915 + 364578 + 684317 + 44530 + 1053802 + 2242204 + 81302 + 2889187 + 1658591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9535147"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1053802+2242204+2889187+1658591+1007046+684317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init person\n",
      "start\n",
      "speak\n",
      "after join\n",
      "start\n",
      "speak\n",
      "after join\n",
      "start\n",
      "speak\n",
      "after join\n",
      "start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3a17e3d9686a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"after join\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    " \n",
    "class Person(object):\n",
    "    def __init__(self):\n",
    "        print(\"init person\")\n",
    " \n",
    "    def speak(self):\n",
    "        print(\"speak\")\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    p = Person()\n",
    "    while True:\n",
    "        timer = threading.Timer(5, Person.speak, (p,))\n",
    "        print(\"start\")\n",
    "        timer.start()\n",
    "        timer.join()\n",
    "        print(\"after join\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "842.516px",
    "left": "1546.97px",
    "right": "20px",
    "top": "116.969px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
