{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas 核心功能文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 写在前面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感谢Zhenmao学长的分享，以下ipython文档在学长分享的基础上做了以下操作：\n",
    "\n",
    "1. 所有文档内容的整合\n",
    "2. 添加了额外的中文说明\n",
    "3. 对于相对复杂的方法、函数，添加官方原档地址，便于随时查阅及拓展学习\n",
    "\n",
    "本册已经全部调整为用Python2编译，可以作为学习过程中具体方法、函数查阅的功能册子。因受能力限制，本册可能存在很多不足之处，欢迎同学们对文中的任何内容提出指导和批评意见，本人会负责对此文档的更新和维护。\n",
    "\n",
    "作者 Bruno Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 显示导入的图片\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Series Initialization and Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Series Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Series Adding/Deleting an Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Adding an element\n",
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "s['d'] = 4\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以其使用drop方法删除不需要的数据，inplace来决定是否在远处修改原来的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "a    1\n",
      "b    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Deleting an element\n",
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "s.drop(['c'], inplace=True)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Series Index and Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas的索引是以从0开始计数的数字和自定义的索引名开展的，选用其中任何一项都适用。可以使用index取出index的描述，index.values取出index的具体值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "Index([u'a', u'b', u'c'], dtype='object')\n",
      "['a' 'b' 'c']\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "print(s.index)\n",
    "print(s.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Reindexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reindex方法重排序索引和指定索引，pandas调用reindex方法后会根据新索引进行重排，并按指定的索引返回对应的内容。\n",
    "\n",
    "官方文档说明连接：http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reindex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "d    NaN\n",
      "c    3.0\n",
      "b    2.0\n",
      "a    1.0\n",
      "dtype: float64\n",
      "Index([u'd', u'c', u'b', u'a'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "\n",
    "# 这里的fill_value=0，如果存在空值则以fill_value里面的内容进行填充\n",
    "# 如果不写则以more的NaN进行填充\n",
    "#s_reindexed = s.reindex(['d', 'c', 'b', 'a'], fill_value=0)\n",
    "s_reindexed = s.reindex(['d', 'c', 'b', 'a'])\n",
    "print(s_reindexed)\n",
    "print(s_reindexed.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "print(s.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    a\n",
      "2    a\n",
      "3    b\n",
      "4    b\n",
      "5    c\n",
      "dtype: object\n",
      "['a' 'b' 'c']\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['a', 'a', 'a', 'b', 'b', 'c'])\n",
    "print(s)\n",
    "print(s.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Series Selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "print(s['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "a    1\n",
      "b    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "\n",
    "# 通常Python中的切片是采取左闭右开的原则，即右边取不到。\n",
    "# 在Series以索引名取值时候，终点值也会被取到。\n",
    "print(s['a':'b']) # Slicing with label, the endpoint is included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 按位置进行取值，不清楚的同学，参考Python列表切片取值。\n",
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "a    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 按位置进行取值的时候，遵守Python列表左闭右开原则，即右边值取不到。\n",
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "print(s[:1]) # Slicing with position, the endpoint is excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Series Sorting and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Sorting by Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照索引标签值对一维数组进行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c    1\n",
      "b    2\n",
      "a    3\n",
      "dtype: int64\n",
      "a    3\n",
      "b    2\n",
      "c    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 按照坐标位置对值进行排序\n",
    "s = pd.Series([1, 2, 3], index=['c', 'b', 'a'])\n",
    "print(s)\n",
    "s_sorted = s.sort_index()\n",
    "print(s_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Sorting by Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照索引值值对一维数组进行排序，排序结果按照从小到大排列\n",
    "\n",
    "官方文档链接：http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    3\n",
      "a    3\n",
      "b    2\n",
      "c    1\n",
      "dtype: int64\n",
      "c    1\n",
      "b    2\n",
      "a    3\n",
      "a    3\n",
      "dtype: int64\n",
      "a    3\n",
      "a    3\n",
      "b    2\n",
      "c    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([3, 3, 2, 1], index=['a', 'a', 'b', 'c'])\n",
    "print(s)\n",
    "s_sorted = s.sort_values()\n",
    "print(s_sorted)\n",
    "\n",
    "# 如果需要换成降序排列，可以指定ascending值，这里的默认值为True。\n",
    "s_sorted = s.sort_values(ascending=False)\n",
    "print(s_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rank函数返回从小到大排序的下标，对于平级的数，rank是通过“为各组分配一个平均排名”的方式破坏平级关系。\n",
    "\n",
    "官方文档连接：http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rank.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "按照索引标签值对一维数组进行排序, 排序方法（method）：\n",
    "method : {‘average’, ‘min’, ‘max’, ‘first’, ‘dense’}\n",
    "1. average: average rank of group\n",
    "2. min: lowest rank in group\n",
    "3. max: highest rank in group\n",
    "4. first: ranks assigned in order they appear in the array\n",
    "5. dense: like ‘min’, but rank always increases by 1 between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    2.0\n",
      "2    3.0\n",
      "3    4.0\n",
      "4    5.0\n",
      "dtype: float64\n",
      "0    1.5\n",
      "1    1.5\n",
      "2    3.0\n",
      "3    4.5\n",
      "4    4.5\n",
      "dtype: float64\n",
      "0    4.5\n",
      "1    4.5\n",
      "2    3.0\n",
      "3    1.5\n",
      "4    1.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 默认排序方法是average\n",
    "s = pd.Series([1, 1, 2, 3, 3])\n",
    "print(s.rank(method='first'))\n",
    "\n",
    "# 如果需要换成降序排列，可以指定ascending值，这里的默认值为True。\n",
    "print(s.rank(method='average'))\n",
    "print(s.rank(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考，排名的时候索引标签是否也会跟着一起动？尝试如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1.0\n",
      "b    2.0\n",
      "c    3.0\n",
      "d    4.0\n",
      "f    5.0\n",
      "dtype: float64\n",
      "a    1.5\n",
      "b    1.5\n",
      "c    3.0\n",
      "d    4.5\n",
      "f    4.5\n",
      "dtype: float64\n",
      "a    4.5\n",
      "b    4.5\n",
      "c    3.0\n",
      "d    1.5\n",
      "f    1.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 默认排序方法是average\n",
    "s = pd.Series([1, 1, 2, 3, 3], index=[\"a\", \"b\", \"c\", \"d\", \"f\"])\n",
    "print(s.rank(method='first'))\n",
    "\n",
    "# 如果需要换成降序排列，可以指定ascending值，这里的默认值为True。\n",
    "print(s.rank(method='average'))\n",
    "print(s.rank(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：排名和排序不同，排名是以某种特定的计算方式计算某一标签值在具体数组中的位置，并不需要调整整个数列的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Series Computatons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与多维数组一起描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.1 Counts of Unique Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过unique方法可以直接获取到不重复数组的元素及其出现次数，可以看做是unique方法的升级版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    a\n",
      "2    a\n",
      "3    c\n",
      "4    c\n",
      "5    c\n",
      "6    b\n",
      "7    b\n",
      "8    c\n",
      "dtype: object\n",
      "c    4\n",
      "a    3\n",
      "b    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['a', 'a', 'a', 'c', 'c', 'c', 'b', 'b', 'c'])\n",
    "print(s)\n",
    "print(s.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.2 Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    a\n",
      "2    a\n",
      "3    b\n",
      "4    b\n",
      "5    c\n",
      "dtype: object\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "5     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['a', 'a', 'a', 'b', 'b', 'c'])\n",
    "print(s)\n",
    "print(s.isin(['b', 'c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6.3 Series Applying Function (Element-wise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series的map方法可以接受一个函数或含有映射关系的字典型对象。 \n",
    "使用map是一种实现元素级转换以及其他数据清理工作的便捷方式。 \n",
    "（DataFrame中对应的是applymap()函数，当然DataFrame还有apply()函数）\n",
    "\n",
    "注意，使用map方法的前提是map里面放置的是一个函数，或者有映射关系的字典类型（键值对）\n",
    "\n",
    "官方文档连接: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n",
      "a    1\n",
      "b    4\n",
      "c    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Series element-wise function application\n",
    "s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
    "print(s)\n",
    "print(s.map(np.square))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考：如果原数列不存在，是否可以无中生有，通过映射直接生成新数列？尝试如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   NaN\n",
      "b   NaN\n",
      "c   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s2 =pd.Series([1,2,3], index = ['a', 'b', 'c'])\n",
    "s = s2.map(s2)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果：无法自己映射自己，实现复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Series Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.1 Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用Count()来统计一维数组中的值得总数，应用于多维数组的info()在这里并不适用, 但是describe()可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    1.0\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    4.0\n",
      "dtype: float64\n",
      "3\n",
      "count    3.000\n",
      "mean     1.667\n",
      "std      2.082\n",
      "min      0.000\n",
      "25%      0.500\n",
      "50%      1.000\n",
      "75%      2.500\n",
      "max      4.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of null values\n",
    "s = pd.Series([0, 1, np.nan, np.nan, 4])\n",
    "print(s)\n",
    "print(s.count())\n",
    "print(s.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.2 Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以通过isnull与notnull方法返回得到一个具体的数组，用于判断是否为空，前者空返回True，非空返回False，后者相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    1.0\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    4.0\n",
      "dtype: float64\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Whether the values are null\n",
    "s = pd.Series([0, 1, np.nan, np.nan, 4])\n",
    "print(s)\n",
    "print(s.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    1.0\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    4.0\n",
      "dtype: float64\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Whether the values are null\n",
    "s = pd.Series([0, 1, np.nan, np.nan, 4])\n",
    "print(s)\n",
    "print(s.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.3 Dropping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是空值处理的一种方法，即在原有数组的基础上将空值行直接舍弃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    1.0\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    4.0\n",
      "dtype: float64\n",
      "0    0.0\n",
      "1    1.0\n",
      "4    4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Drop the null values\n",
    "s = pd.Series([0, 1, np.nan, np.nan, 4])\n",
    "print(s)\n",
    "s_dropped = s.dropna()\n",
    "print(s_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7.4 Filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是处理空值的另一种方法，即对空值进行填充，除了填充固定值以外，也可以考虑计算得到例如众值，均数等值进行填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "1    1.0\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    4.0\n",
      "dtype: float64\n",
      "0      0.0\n",
      "1      1.0\n",
      "2    999.0\n",
      "3    999.0\n",
      "4      4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fill the null values\n",
    "s = pd.Series([0, 1, np.nan, np.nan, 4])\n",
    "print(s)\n",
    "s_filled = s.fillna(999)\n",
    "print(s_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DataFrame Initialization and Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 DataFrame Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_0  col_1\n",
      "0      0      1\n",
      "1     10     11\n",
      "2     20     21\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    })\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': {'row_0': 0, 'row_1': 10, 'row_2': 20},\n",
    "        'col_1': {'row_0': 1, 'row_1': 11, 'row_2': 21}\n",
    "    })\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 DataFrame Adding/Deleting a Row/Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also 5 Combining Multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_0  col_1  col_2\n",
      "row_0      0      1      2\n",
      "row_1     10     11     21\n",
      "row_2     20     21     22\n"
     ]
    }
   ],
   "source": [
    "# Adding a column\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "df['col_2'] = [2, 21, 22]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "col_0    30\n",
      "col_1    31\n",
      "Name: row_3, dtype: int64\n",
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_3     30     31\n"
     ]
    }
   ],
   "source": [
    "# Adding a row 按照一维数组的形式添加\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "s = pd.Series([30, 31], index=['col_0', 'col_1'], name='row_3')\n",
    "print(s)\n",
    "df = df.append(s)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要特别注意的inplace参数：\n",
    "\n",
    "Series 和 DataFrame 对象的方法中，凡是会对数组作出修改并返回一个新数组的，往往都有一个 inplace=False 的可选参数。如果手动设定为 True，那么原数组就可以被替换。 下面案例说明中具体阐述了上面的现象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修改前数组所在的内存地址为: 54637584\n",
      "修改后原数组所在的内存地址为: 54637584\n",
      "修改后新数组所在的内存地址为: 54525840\n"
     ]
    }
   ],
   "source": [
    "# Deleting a column 删除一列\n",
    "# inplace默认为False，意思是在新的内存地址生成数组\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "\n",
    "# 使用Python的id()方法可以打印数组所在的内存地址\n",
    "\n",
    "# 首先查看df所在内存地址为\n",
    "print(\"修改前数组所在的内存地址为: %s\" % id(df))\n",
    "\n",
    "# 如果选择默认inplace修改，即在生成新的数组，df1将指向新数组（内存地址）且原数组地址不变，仅发生内容修改。\n",
    "df1 = df.drop('col_1', axis=1, inplace=False)\n",
    "print(\"修改后原数组所在的内存地址为: %s\" % id(df))\n",
    "print(\"修改后新数组所在的内存地址为: %s\" % id(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修改前数组所在的内存地址为: 54637456\n",
      "修改后原数组所在的内存地址为: 54637456\n",
      "修改后df1为: None\n"
     ]
    }
   ],
   "source": [
    "# Deleting a column 删除一列\n",
    "# inplace默认为False，意思是在新的内存地址生成数组\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "\n",
    "# 如果选择inplace=True修改，即在原内存地址进行修改，df1将被赋值为空，因为drop操作并没有返回任何内容。\n",
    "# 首先查看df所在内存地址为\n",
    "print(\"修改前数组所在的内存地址为: %s\" % id(df))\n",
    "\n",
    "# 如果选择默认inplace修改，即在生成新的数组，df1将指向新数组（内存地址）且原数组地址不变。\n",
    "df1 = df.drop('col_1', axis=1, inplace=True)\n",
    "print(\"修改后原数组所在的内存地址为: %s\" % id(df))\n",
    "print(\"修改后df1为: %s\" % df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n"
     ]
    }
   ],
   "source": [
    "# Deleting a row 删除一行\n",
    "# 注意默认的删除是axis=0，即删除行。所以如果是想删除行，可以不用指出axis值\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "df.drop('row_0', inplace=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2 DataFrame Index, Columns and Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.2.1 Index (Row Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "Index([u'row_0', u'row_1', u'row_2'], dtype='object')\n",
      "['row_0' 'row_1' 'row_2']\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.index)\n",
    "print(df.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.2.2 Columns (Column Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "Index([u'col_0', u'col_1'], dtype='object')\n",
      "['col_0' 'col_1']\n"
     ]
    }
   ],
   "source": [
    "# DataFrame columns\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.columns)\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### 3.3.3 Reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_0  col_1\n",
      "row_2     20     21\n",
      "row_1     10     11\n",
      "row_0      0      1\n"
     ]
    }
   ],
   "source": [
    "# 按照行对数值进行位置调整，并不影响index和元素之间的绑定关系\n",
    "# Reindexing rows\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "df_reindexed = df.reindex(index=['row_2', 'row_1', 'row_0'])\n",
    "print(df_reindexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_1  col_0\n",
      "row_0      1      0\n",
      "row_1     11     10\n",
      "row_2     21     20\n"
     ]
    }
   ],
   "source": [
    "# Reindexing columns\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "df_reindexed = df.reindex(columns=['col_1', 'col_0'])\n",
    "print(df_reindexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3.4 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "[[ 0  1]\n",
      " [10 11]\n",
      " [20 21]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3.5 Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       row_0  row_1  row_2\n",
      "col_0      0     10     20\n",
      "col_1      1     11     21\n"
     ]
    }
   ],
   "source": [
    "# 这个功能和excel转置类似，即将数组的行和列对换，但是互相之间的对应关系不发生改变\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3 DataFrame Selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结Pandas数组的分布规则入下，后续还会大量遇到：\n",
    "\n",
    "1. axis=0轴，为纵轴，也可以表述为index\n",
    "2. axis=1轴，为横轴，也可以表述为columns\n",
    "\n",
    "在二维数组中（如果有），第一项表示axis=0，即index；第二项表示axis=1，即columns\n",
    "\n",
    "axis轴关系描述图如下：http://upload-images.jianshu.io/upload_images/2233157-b77105789e36c847.jpg?imageMogr2/auto-orient/strip%7CimageView2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3.1 Label with .loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".loc方法，可以按照列名、行名对二维数组进行取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0     0\n",
      "row_1    10\n",
      "row_2    20\n",
      "Name: col_0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df.loc[:, col_label] selecting columns\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.loc[:, 'col_0']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "col_0    0\n",
      "col_1    1\n",
      "Name: row_0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df.loc[row_label] selecting rows\n",
    "\n",
    "# 在二维数组中单独写index名，表示取出相应的行\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.loc['row_0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3.2 Position with .iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".iloc方法按照行、列坐标值进行取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0     0\n",
      "row_1    10\n",
      "row_2    20\n",
      "Name: col_0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df.iloc[:, col_position] selecting columns\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_0  col_1\n",
      "row_1     10     11\n"
     ]
    }
   ],
   "source": [
    "# df.iloc[row_position] selecting rows\n",
    "# 与loc方法相同，如果仅仅是一个数字，表示取相对应行的值，也便是从axis=0轴上取某个index的一整行\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.iloc[1:2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3.3 Mixing Label and Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# df.loc[df.index[row_position], col_label]\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.loc[df.index[2], 'col_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# df.loc[row_label, df.colums[col_position]]\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.loc['row_2', df.columns[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3.4 With [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0     0\n",
      "row_1    10\n",
      "row_2    20\n",
      "Name: col_0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# df[col_label] selects columns\n",
    "\n",
    "# 与loc方法取行不同的是，直接写df['名字']可以取出列值\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df['col_0']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_0  col_1\n",
      "row_1     10     11\n",
      "       col_0  col_1\n",
      "row_1     10     11\n"
     ]
    }
   ],
   "source": [
    "# Convenience 1: [] with a slice to slice rows\n",
    "# df[row_position_slice]\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df[1:2])\n",
    "\n",
    "# 这里的这种取值方法等同于按照iloc方法来取值\n",
    "\n",
    "print(df.iloc[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0    False\n",
      "row_1     True\n",
      "row_2     True\n",
      "Name: col_1, dtype: bool\n",
      "<class 'pandas.core.series.Series'>\n",
      "       col_0  col_1\n",
      "row_1     10     11\n",
      "row_2     20     21\n"
     ]
    }
   ],
   "source": [
    "# Convenience 2: [] with a boolean array to filter rows\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df['col_1']>10) # Returns a boolean series # 这里有修改，返回值其实是一维数组\n",
    "print(type(df[\"col_1\"]))\n",
    "print(df[df['col_1']>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_1     10     11\n",
      "row_2     20     21\n"
     ]
    }
   ],
   "source": [
    "series = np.array([False, True, True])\n",
    "print(df[series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_0  col_1\n",
      "row_0  False  False\n",
      "row_1  False   True\n",
      "row_2   True   True\n",
      "       col_0  col_1\n",
      "row_0    NaN    NaN\n",
      "row_1    NaN   11.0\n",
      "row_2   20.0   21.0\n",
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10    999\n",
      "row_2    999    999\n"
     ]
    }
   ],
   "source": [
    "# Convenience 3: [] with a boolean DataFrame to filter element\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df>10)\n",
    "print(df[df>10])\n",
    "# This is used to set values elementwise based on some criterion\n",
    "df[df>10] = 999\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.4 DataFrame Sorting and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.4.1 Sorting by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_2  col_1  col_0\n",
      "row_2      0      1      2\n",
      "row_1      3      4      5\n",
      "row_4      6      7      8\n",
      "       col_2  col_1  col_0\n",
      "row_1      3      4      5\n",
      "row_2      0      1      2\n",
      "row_4      6      7      8\n"
     ]
    }
   ],
   "source": [
    "# Sort rows by index\n",
    "\n",
    "# 以下是快速创建numpy数组的方法，简单的说来Pandas数组是在nupmy数组的基础上加上了轴名\n",
    "df = pd.DataFrame(np.arange(9).reshape((3,3)),\n",
    "                  index=['row_2', 'row_1', 'row_4'],\n",
    "                  columns=['col_2', 'col_1', 'col_0'])\n",
    "print(df)\n",
    "\n",
    "# 这里的排序存在其内在的算法，即便名字不完全相同也可以进行排序。\n",
    "df_sorted = df.sort_index()\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     col_2  col_1  col_0\n",
      "100      0      1      2\n",
      "aa       3      4      5\n",
      "a1       6      7      8\n",
      "     col_2  col_1  col_0\n",
      "100      0      1      2\n",
      "a1       6      7      8\n",
      "aa       3      4      5\n"
     ]
    }
   ],
   "source": [
    "# Sort rows by index 名字不相同时候的排序\n",
    "df = pd.DataFrame(np.arange(9).reshape((3,3)),\n",
    "                  index=['100', 'aa', 'a1'],\n",
    "                  columns=['col_2', 'col_1', 'col_0'])\n",
    "print(df)\n",
    "# 欢迎有兴趣的同学可以对这点进行探索，即排序值的计算\n",
    "#目前发现的规律有以下几种：数字比字母小；字母按照从a到z来排；大写字母优先于小写；首字母相同按照不相同的开始排序计算\n",
    "df_sorted = df.sort_index()\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_2  col_1  col_0\n",
      "row_2      0      1      2\n",
      "row_1      3      4      5\n",
      "row_0      6      7      8\n",
      "       col_0  col_1  col_2\n",
      "row_2      2      1      0\n",
      "row_1      5      4      3\n",
      "row_0      8      7      6\n"
     ]
    }
   ],
   "source": [
    "# Sort columns by index\n",
    "df = pd.DataFrame(np.arange(9).reshape((3,3)),\n",
    "                  index=['row_2', 'row_1', 'row_0'],\n",
    "                  columns=['col_2', 'col_1', 'col_0'])\n",
    "print(df)\n",
    "\n",
    "# 对列进行排序\n",
    "df_sorted = df.sort_index(axis=1)\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.4.2 Sorting by Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1  col_2\n",
      "row_0      8      7      6\n",
      "row_1      5      4      3\n",
      "row_2      2      1      0\n",
      "       col_0  col_1  col_2\n",
      "row_2      2      1      0\n",
      "row_1      5      4      3\n",
      "row_0      8      7      6\n"
     ]
    }
   ],
   "source": [
    "# Sort rows by values\n",
    "df = pd.DataFrame(np.arange(9)[::-1].reshape((3,3)),\n",
    "                  index=['row_0', 'row_1', 'row_2'],\n",
    "                  columns=['col_0', 'col_1', 'col_2'])\n",
    "print(df)\n",
    "\n",
    "# 以第一列为参考对值进行排序，这里axis=0作为默认参数可以隐藏不写\n",
    "df_sorted = df.sort_values(by=['col_0'], axis=0)\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1  col_2\n",
      "row_0      8      7      6\n",
      "row_1      5      4      3\n",
      "row_2      2      1      0\n",
      "       col_0  col_1  col_2\n",
      "row_0      8      7      6\n",
      "row_1      5      4      3\n",
      "row_2      2      1      0\n"
     ]
    }
   ],
   "source": [
    "# Sort columns by values\n",
    "df = pd.DataFrame(np.arange(9)[::-1].reshape((3,3)),\n",
    "                  index=['row_0', 'row_1', 'row_2'],\n",
    "                  columns=['col_0', 'col_1', 'col_2'])\n",
    "print(df)\n",
    "\n",
    "# 如果需要按照行的值进行排序，需要写上行名，然后调整axis=1, 同时也可以设置ascending来指定升序还是降序\n",
    "df_sorted = df.sort_values(by=['row_0'], axis=1, ascending=False)\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.4.3 Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  3  4\n",
      "1  2  5\n",
      "2  1  4\n",
      "3  0  5\n",
      "     0    1\n",
      "0  4.0  1.0\n",
      "1  3.0  3.0\n",
      "2  2.0  2.0\n",
      "3  1.0  4.0\n"
     ]
    }
   ],
   "source": [
    "# 类似于series，这里可以指定max, average, first等作为排名方法\n",
    "# 排名仅会对值在数组中的大小进行比较，然后返回一个编号，默认从小到大，但是并不会改变原数组的结构\n",
    "df = pd.DataFrame([\n",
    "    [3, 4],\n",
    "    [2, 5],\n",
    "    [1, 4],\n",
    "    [0, 5]\n",
    "])\n",
    "print(df)\n",
    "print(df.rank(method='first'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.5 DataFrame Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.5.1 Maximum Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     41\n",
      "row_2     20     21\n",
      "col_0    20\n",
      "col_1    41\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 41, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Maximum Value Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     41\n",
      "row_2     20     21\n",
      "col_0    row_2\n",
      "col_1    row_1\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 可以通过idxmax方法取出数组的最大值所在的位置\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 41, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.5.3 Minimum Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0     0\n",
      "row_1    10\n",
      "row_2    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 可以通过指定axis=1对行元素进行数值大小的比较，返回得到最大值所在的列\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.min(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4 Minimum Value Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0    col_0\n",
      "row_1    col_0\n",
      "row_2    col_0\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.idxmin(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.5.5 Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0     0.5\n",
      "row_1    10.5\n",
      "row_2    20.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.5.6 Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "col_0    10.0\n",
      "col_1    11.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.5.7 Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "col_0    30\n",
      "col_1    33\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.6 DataFrame Applying Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.6.1 Element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1    100    121\n",
      "row_2    400    441\n"
     ]
    }
   ],
   "source": [
    "# DataFrame element-wise function application\n",
    "\n",
    "# 这个功能和series中的map一样\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.applymap(np.square))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.6.2 Column-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "col_0    20\n",
      "col_1    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# DataFrame column-wise function application\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "\n",
    "# 这里的lambda为匿名函数\n",
    "print(df.apply(lambda x: x.max() - x.min(), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.6.3 Row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0      0      1\n",
      "row_1     10     11\n",
      "row_2     20     21\n",
      "row_0    1\n",
      "row_1    1\n",
      "row_2    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# DataFrame row-wise function application\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, 20],\n",
    "        'col_1': [1, 11, 21]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.apply(lambda x: x.max() - x.min(), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.7 DataFrame Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.7.1 Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0    NaN\n",
      "row_2    NaN    NaN\n",
      "col_0    2\n",
      "col_1    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of null values\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, np.nan],\n",
    "        'col_1': [1, np.nan, np.nan]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.7.2 Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0    NaN\n",
      "row_2    NaN    NaN\n",
      "       col_0  col_1\n",
      "row_0  False  False\n",
      "row_1  False   True\n",
      "row_2   True   True\n"
     ]
    }
   ],
   "source": [
    "# Whether the values are null\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, np.nan],\n",
    "        'col_1': [1, np.nan, np.nan]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0    NaN\n",
      "row_2    NaN    NaN\n",
      "       col_0  col_1\n",
      "row_0   True   True\n",
      "row_1   True  False\n",
      "row_2  False  False\n"
     ]
    }
   ],
   "source": [
    "# Whether the values are not null\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, np.nan],\n",
    "        'col_1': [1, np.nan, np.nan]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "print(df.notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.7.3 Dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0    NaN\n",
      "row_2    NaN    NaN\n",
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with ANY null values\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, np.nan],\n",
    "        'col_1': [1, np.nan, np.nan]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.7.4 Filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0    NaN\n",
      "row_2    NaN    NaN\n",
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0  999.0\n",
      "row_2  999.0  999.0\n"
     ]
    }
   ],
   "source": [
    "# Fill the null values\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, np.nan],\n",
    "        'col_1': [1, np.nan, np.nan]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "df_filled = df.fillna(999)\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0    NaN\n",
      "row_2    NaN    NaN\n",
      "       col_0  col_1\n",
      "row_0    0.0    1.0\n",
      "row_1   10.0  888.0\n",
      "row_2  777.0  888.0\n"
     ]
    }
   ],
   "source": [
    "# Fill the null values, column specific\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 10, np.nan],\n",
    "        'col_1': [1, np.nan, np.nan]\n",
    "    }, index = ['row_0', 'row_1', 'row_2'])\n",
    "print(df)\n",
    "df_filled = df.fillna({'col_0': 777, 'col_1': 888})\n",
    "print(df_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了读取CSV格式文件外，Pandas也可以完成对很多其他格式文件的读取，为了方便以后使用，留存链接如下：\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.1 Reading CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 直接读取\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cat file1.csv\n",
    "df = pd.read_csv('file1.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 读取时加上\"\\t\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Tab delimited file 这里的\\t为制表符，表示tab缩进\n",
    "!cat file2.txt\n",
    "df = pd.read_csv('file2.txt', sep='\\t')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 取消标题"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CSV file with no headers\n",
    "!cat file3.csv\n",
    "df = pd.read_csv('file3.csv', header=None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 对无标题CSV添加标题"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add headers to no header CSV file\n",
    "!cat file3.csv\n",
    "df = pd.read_csv('file3.csv', \n",
    "                 names=['Rank', 'Language', 'L1 speakers', 'Total'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.5 将其中一列作为index列"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Set one CSV column as DataFrame index\n",
    "!cat file1.csv\n",
    "df = pd.read_csv('file1.csv', index_col='Rank')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.6 读CSV文件时，跳过行"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Skip rows of CSV file\n",
    "!cat file4.csv\n",
    "df = pd.read_csv('file4.csv', skiprows=2) # 跳过文件最开始的两行\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.7 读文件时，空值的处理 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CSV with missing values\n",
    "!cat file5.csv\n",
    "df = pd.read_csv('file5.csv')\n",
    "print(df)\n",
    "# By default the following values are interpreted as NaN: \n",
    "#‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, \n",
    "#‘1.#IND’, ‘1.#QNAN’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘nan’`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.8 读取文件其中几行"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read a small number of rows\n",
    "!cat file1.csv\n",
    "df = pd.read_csv('file1.csv', nrows=3)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.9 以Chunk方式读取，减少内存占用"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read in chunks for large CSV files\n",
    "!cat file1.csv\n",
    "reader = pd.read_csv('file1.csv', chunksize=2)\n",
    "for chunck in reader:\n",
    "    print(chunck)\n",
    "# The return value is an iterable TextFileReader object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.2 Writing CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 默认导出格式，包含索引"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# With DataFrame index\n",
    "df = pd.read_csv('file1.csv')\n",
    "print(df)\n",
    "df.to_csv('file_out1.csv')\n",
    "!cat file_out1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 修改导出格式，删除索引"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# No DataFrame index\n",
    "df = pd.read_csv('file1.csv')\n",
    "print(df)\n",
    "df.to_csv('file_out2.csv', index=False)\n",
    "!cat file_out2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Combining Multiple DataFrames"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "更多的官方文档在如下连接\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5.1 Database-Style DataFrame Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.1.1 Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并关系有三种，分别是：\n",
    "1. One-to-one\tJoin two columns that contain unique values\n",
    "2. Many-to-one\tJoin one column that contains non-unique values with another column that contains unique values\n",
    "3. Many-to-many\tJoin two columns that contain non-unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K1\n",
      "    B key\n",
      "0  B0  K0\n",
      "1  B1  K1\n",
      "    A key   B\n",
      "0  A0  K0  B0\n",
      "1  A1  K1  B1\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge one-to-one 一对一合并\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K0\n",
      "    B key\n",
      "0  B0  K0\n",
      "    A key   B\n",
      "0  A0  K0  B0\n",
      "1  A1  K0  B0\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge many-to-one 多对1合并\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K0']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0'],\n",
    "        'key': ['K0']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K0\n",
      "    B key\n",
      "0  B0  K0\n",
      "1  B1  K0\n",
      "    A key   B\n",
      "0  A0  K0  B0\n",
      "1  A0  K0  B1\n",
      "2  A1  K0  B0\n",
      "3  A1  K0  B1\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge many-to-many\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K0']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1'],\n",
    "        'key': ['K0', 'K0']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.1.2 Merge Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并的方法有四种，操作和数据库操作类似：\n",
    "1. Inner\tUse intersection of keys from both DataFrames 内连接\n",
    "2. Outer\tUse union of keys from both DataFrames 外连接\n",
    "3. Left\tUse keys from left DataFrame only 左连接\n",
    "4. Right\tUse keys from right DataFrame only 右连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K1\n",
      "    B key\n",
      "0  B0  K0\n",
      "1  B1  K2\n",
      "    A key   B\n",
      "0  A0  K0  B0\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge method inner 仅对相同的公共部分进行连接，默认为内连接\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1'],\n",
    "        'key': ['K0', 'K2']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key') # default how='inner'\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K1\n",
      "    B key\n",
      "0  B0  K0\n",
      "1  B1  K2\n",
      "     A key    B\n",
      "0   A0  K0   B0\n",
      "1   A1  K1  NaN\n",
      "2  NaN  K2   B1\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge method outer # 左右两边都会被保留，如果在另一张表没有找到就留空\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1'],\n",
    "        'key': ['K0', 'K2']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key', how='outer')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K1\n",
      "    B key\n",
      "0  B0  K0\n",
      "1  B1  K2\n",
      "    A key    B\n",
      "0  A0  K0   B0\n",
      "1  A1  K1  NaN\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge method left # 以左表为参照，左表内容在右表没有找到的就留空\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1'],\n",
    "        'key': ['K0', 'K2']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key', how='left')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K1\n",
      "    B key\n",
      "0  B0  K0\n",
      "1  B1  K2\n",
      "     A key   B\n",
      "0   A0  K0  B0\n",
      "1  NaN  K2  B1\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge method right 以右表为参照，右表内容在右表没有找到的就留空\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1'],\n",
    "        'key': ['K0', 'K2']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key', how='right')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.1.3 Merge on Keys (Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key_l\n",
      "0  A0    K0\n",
      "1  A1    K1\n",
      "    B key_r\n",
      "0  B0    K0\n",
      "1  B1    K1\n",
      "    A key_l   B key_r\n",
      "0  A0    K0  B0    K0\n",
      "1  A1    K1  B1    K1\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge with different key names (columns)\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key_l': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1'],\n",
    "        'key_r': ['K0', 'K1']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, left_on='key_l', right_on='key_r')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key1 key2\n",
      "0  A0   K0   L0\n",
      "1  A1   K1   L0\n",
      "    B key1 key2\n",
      "0  B1   K0   L0\n",
      "1  B2   K0   L1\n",
      "     A key1 key2    B\n",
      "0   A0   K0   L0   B1\n",
      "1   A1   K1   L0  NaN\n",
      "2  NaN   K0   L1   B2\n"
     ]
    }
   ],
   "source": [
    "# DataFrame merge on multiple keys (columns)\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key1': ['K0', 'K1'],\n",
    "        'key2': ['L0', 'L0']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B1', 'B2'],\n",
    "        'key1': ['K0', 'K0'],\n",
    "        'key2': ['L0', 'L1']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on=['key1', 'key2'], how='outer')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.1.4 Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  L0  K0\n",
      "1  L1  K1\n",
      "    A key\n",
      "0  R2  K0\n",
      "1  R3  K1\n",
      "  A_x key A_y\n",
      "0  L0  K0  R2\n",
      "1  L1  K1  R3\n"
     ]
    }
   ],
   "source": [
    "# Same column name\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['L0', 'L1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'A': ['R2', 'R3'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  L0  K0\n",
      "1  L1  K1\n",
      "    A key\n",
      "0  R2  K0\n",
      "1  R3  K1\n",
      "  A_l key A_r\n",
      "0  L0  K0  R2\n",
      "1  L1  K1  R3\n"
     ]
    }
   ],
   "source": [
    "# Add suffixes to the same column name\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['L0', 'L1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'A': ['R2', 'R3'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, on='key', suffixes=('_l', '_r'))\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.1.5 Merge on Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A\n",
      "K0  A0\n",
      "K1  A1\n",
      "     B\n",
      "K0  B0\n",
      "K1  B1\n",
      "     A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n"
     ]
    }
   ],
   "source": [
    "# Merge on index\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1']\n",
    "    }, index=['K0', 'K1'])\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1']\n",
    "    }, index=['K0', 'K1'])\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, left_index=True, right_index=True)\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A key\n",
      "0  A0  K0\n",
      "1  A1  K1\n",
      "     B\n",
      "K0  B0\n",
      "K1  B1\n",
      "    A key   B\n",
      "0  A0  K0  B0\n",
      "1  A1  K1  B1\n"
     ]
    }
   ],
   "source": [
    "# Merge on index and key\n",
    "df_l = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'key': ['K0', 'K1']\n",
    "    })\n",
    "df_r = pd.DataFrame({\n",
    "        'B': ['B0', 'B1']\n",
    "    }, index=['K0', 'K1'])\n",
    "print(df_l)\n",
    "print(df_r)\n",
    "df_merged = pd.merge(df_l, df_r, left_on='key', right_index=True)\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5.2 Concatenating DataFrames Along an Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.2.1 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "a  A0  B0\n",
      "b  A1  B1\n",
      "    A   B\n",
      "c  A2  B2\n",
      "d  A3  B3\n",
      "    A   B\n",
      "a  A0  B0\n",
      "b  A1  B1\n",
      "c  A2  B2\n",
      "d  A3  B3\n"
     ]
    }
   ],
   "source": [
    "# Keeping original indexes 直接使用concat是在原表的基础上继续按行添加\n",
    "df1 = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'B': ['B0', 'B1']\n",
    "    }, index=['a', 'b'])\n",
    "df2 = pd.DataFrame({\n",
    "        'A': ['A2', 'A3'],\n",
    "        'B': ['B2', 'B3']\n",
    "    }, index=['c', 'd'])\n",
    "print(df1)\n",
    "print(df2)\n",
    "df_concat = pd.concat([df1, df2])\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "a  A0  B0\n",
      "b  A1  B1\n",
      "    A   B\n",
      "c  A2  B2\n",
      "d  A3  B3\n",
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "3  A3  B3\n"
     ]
    }
   ],
   "source": [
    "# Ignoring original indexes # 在合并的过程中，忽略掉原列名\n",
    "df1 = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'B': ['B0', 'B1']\n",
    "    }, index=['a', 'b'])\n",
    "df2 = pd.DataFrame({\n",
    "        'A': ['A2', 'A3'],\n",
    "        'B': ['B2', 'B3']\n",
    "    }, index=['c', 'd'])\n",
    "print(df1)\n",
    "print(df2)\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "a  A0  B0\n",
      "b  A1  B1\n",
      "    A   B\n",
      "c  A2  B2\n",
      "d  A3  B3\n",
      "      A   B\n",
      "x a  A0  B0\n",
      "  b  A1  B1\n",
      "y c  A2  B2\n",
      "  d  A3  B3\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical index on the concatenation axis # 在原有的index基础上再套一层，做成multiindex结构\n",
    "df1 = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'B': ['B0', 'B1']\n",
    "    }, index=['a', 'b'])\n",
    "df2 = pd.DataFrame({\n",
    "        'A': ['A2', 'A3'],\n",
    "        'B': ['B2', 'B3']\n",
    "    }, index=['c', 'd'])\n",
    "print(df1)\n",
    "print(df2)\n",
    "df_concat = pd.concat([df1, df2], keys=['x', 'y'])\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.2.2 Concatenating Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "    C   D\n",
      "0  C0  D0\n",
      "1  C1  D1\n",
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'B': ['B0', 'B1']\n",
    "    })\n",
    "df2 = pd.DataFrame({\n",
    "        'C': ['C0', 'C1'],\n",
    "        'D': ['D0', 'D1']\n",
    "    })\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "# 按行进行拼接\n",
    "df_concat = pd.concat([df1, df2], axis=1)\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.2.3 Logic on the Other Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "    B   C\n",
      "2  B2  C2\n",
      "4  B3  C3\n",
      "    B\n",
      "0  B0\n",
      "1  B1\n",
      "2  B2\n",
      "4  B3\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "df1 = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'B': ['B0', 'B1']\n",
    "    }, index=[0, 1])\n",
    "df2 = pd.DataFrame({\n",
    "        'B': ['B2', 'B3'],\n",
    "        'C': ['C2', 'C3']\n",
    "    }, index=[2, 4])\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "# 默认案列进行拼接，所以列名相同就可以被接起来\n",
    "df_concat = pd.concat([df1, df2], join='inner')\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "    B   C\n",
      "2  B2  C2\n",
      "3  B3  C3\n",
      "     A   B    C\n",
      "0   A0  B0  NaN\n",
      "1   A1  B1  NaN\n",
      "2  NaN  B2   C2\n",
      "3  NaN  B3   C3\n"
     ]
    }
   ],
   "source": [
    "# Outer join\n",
    "df1 = pd.DataFrame({\n",
    "        'A': ['A0', 'A1'],\n",
    "        'B': ['B0', 'B1']\n",
    "    }, index=[0, 1])\n",
    "df2 = pd.DataFrame({\n",
    "        'B': ['B2', 'B3'],\n",
    "        'C': ['C2', 'C3']\n",
    "    }, index=[2, 3])\n",
    "print(df1)\n",
    "print(df2)\n",
    "df_concat = pd.concat([df1, df2]) # default join='outer'\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Reshaping and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6.1 Reshaping and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Pivoting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 创建数据透视表，类似于excel中的数透表\n",
    "\n",
    "案例材料如下：\n",
    "\n",
    "数组格式\n",
    "         date      city  min_temp_C  max_temp_C\n",
    "0  2017-01-01    London           4          10\n",
    "1  2017-01-01  New York           5           8\n",
    "2  2017-01-01  Shanghai           5          15\n",
    "3  2017-01-02    London          -1           5\n",
    "4  2017-01-02  New York           3           4\n",
    "5  2017-01-02  Shanghai           8          15\n",
    "6  2017-01-03    London          -2           5\n",
    "7  2017-01-03  New York           4           6\n",
    "8  2017-01-03  Shanghai           7          14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_pivoted = df.pivot(index='date', columns='city', values='min_temp_C')\n",
    "\n",
    "city        London  New York  Shanghai\n",
    "date                                  \n",
    "2017-01-01       4         5         5\n",
    "2017-01-02      -1         3         8\n",
    "2017-01-03      -2         4         7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# If values are not specified, all remaining columns will be used \n",
    "# and the result will have hierarchically indexed columns\n",
    "\n",
    "df_pivoted = df.pivot(index='date', columns='city')\n",
    "city           London New York Shanghai     London New York Shanghai\n",
    "date                                                                \n",
    "2017-01-01          4        5        5         10        8       15\n",
    "2017-01-02         -1        3        8          5        4       15\n",
    "2017-01-03         -2        4        7          5        6       14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6.1.2 Stacking and Unstacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y\n",
      "a  1  2\n",
      "b  3  4\n",
      "a  X    1\n",
      "   Y    2\n",
      "b  X    3\n",
      "   Y    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 将行索引逆转称为列索引，实现层次化索引, 如果原有数组为二维，则将二维数组转换为一维数组\n",
    "\n",
    "# 案例一\n",
    "df = pd.DataFrame([[1, 2],\n",
    "                   [3, 4]],\n",
    "                  index=['a', 'b'],\n",
    "                  columns=['X', 'Y'])\n",
    "print(df)\n",
    "print(df.stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y  Z\n",
      "a  1  2  3\n",
      "b  4  5  6\n",
      "c  7  8  9\n",
      "a  X    1\n",
      "   Y    2\n",
      "   Z    3\n",
      "b  X    4\n",
      "   Y    5\n",
      "   Z    6\n",
      "c  X    7\n",
      "   Y    8\n",
      "   Z    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 案例二\n",
    "df = pd.DataFrame([[1, 2, 3],\n",
    "                   [4, 5, 6],[7, 8, 9]],\n",
    "                  index=['a', 'b', 'c'],\n",
    "                  columns=['X', 'Y', 'Z'])\n",
    "print(df)\n",
    "print(df.stack())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Unstack pivots a level of the row index to the column axis\n",
    "# unstack将列级索引转化为行级索引\n",
    "print(df)\n",
    "df_unstacked = df.unstack()\n",
    "print(df_unstacked)\n",
    "\n",
    "                     min_temp_C  max_temp_C\n",
    "date       city                            \n",
    "2017-01-01 London             4          10\n",
    "           New York           5           8\n",
    "           Shanghai           5          15\n",
    "2017-01-02 London            -1           5\n",
    "           New York           3           4\n",
    "           Shanghai           8          15\n",
    "2017-01-03 London            -2           5\n",
    "           New York           4           6\n",
    "           Shanghai           7          14\n",
    "           min_temp_C                   max_temp_C\n",
    "   \n",
    "city           London New York Shanghai     London New York Shanghai\n",
    "date                                                                \n",
    "2017-01-01          4        5        5         10        8       15\n",
    "2017-01-02         -1        3        8          5        4       15\n",
    "2017-01-03         -2        4        7          5        6       14"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Stack pivots a level of the column labels to the row axis\n",
    "# stack为unstack的逆转，将行级索引转化为列级索引\n",
    "df = df_unstacked\n",
    "print(df)\n",
    "df_stacked = df.stack()\n",
    "print(df_stacked)\n",
    "\n",
    "           min_temp_C                   max_temp_C                  \n",
    "city           London New York Shanghai     London New York Shanghai\n",
    "date                                                                \n",
    "2017-01-01          4        5        5         10        8       15\n",
    "2017-01-02         -1        3        8          5        4       15\n",
    "2017-01-03         -2        4        7          5        6       14\n",
    "\n",
    "                     min_temp_C  max_temp_C\n",
    "date       city                            \n",
    "2017-01-01 London             4          10\n",
    "           New York           5           8\n",
    "           Shanghai           5          15\n",
    "2017-01-02 London            -1           5\n",
    "           New York           3           4\n",
    "           Shanghai           8          15\n",
    "2017-01-03 London            -2           5\n",
    "           New York           4           6\n",
    "           Shanghai           7          14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6.2 Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6.2.1 Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_0  col_1\n",
      "0      0      0\n",
      "1      0      0\n",
      "2      1      2\n",
      "3      1      3\n",
      "   col_0  col_1\n",
      "0      0      0\n",
      "2      1      2\n",
      "3      1      3\n"
     ]
    }
   ],
   "source": [
    "# 案例一\n",
    "# 默认保留第一次出现的值，同时行索引并不会改变，而是保留原有的数值。\n",
    "# Across all columns\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 0, 1, 1],\n",
    "        'col_1': [0, 0, 2, 3]\n",
    "    })\n",
    "print(df)\n",
    "df_deduplicated = df.drop_duplicates() # default keep='first'\n",
    "print(df_deduplicated)\n",
    "# keep\n",
    "# first: Drop duplicates except for the first occurrence.\n",
    "# last: Drop duplicates except for the last occurrence.\n",
    "# False: Drop all duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_0  col_1\n",
      "0      0      0\n",
      "1      0      0\n",
      "2      1      2\n",
      "3      1      3\n",
      "   col_0  col_1\n",
      "2      1      2\n",
      "3      1      3\n"
     ]
    }
   ],
   "source": [
    "# 案例二\n",
    "# Across all columns\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 0, 1, 1],\n",
    "        'col_1': [0, 0, 2, 3]\n",
    "    })\n",
    "print(df)\n",
    "df_deduplicated = df.drop_duplicates(keep=False) # default keep='first'\n",
    "print(df_deduplicated)\n",
    "# keep\n",
    "# first: Drop duplicates except for the first occurrence.\n",
    "# last: Drop duplicates except for the last occurrence.\n",
    "# False: Drop all duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col_0  col_1\n",
      "0      0      0\n",
      "1      0      0\n",
      "2      1      2\n",
      "3      1      3\n",
      "   col_0  col_1\n",
      "0      0      0\n",
      "2      1      2\n"
     ]
    }
   ],
   "source": [
    "# 指明特定的列以此列为参照，只要这一列有重复，就整行的值。\n",
    "# Specifying columns\n",
    "df = pd.DataFrame({\n",
    "        'col_0': [0, 0, 1, 1],\n",
    "        'col_1': [0, 0, 2, 3]\n",
    "    })\n",
    "print(df)\n",
    "df_deduplicated = df.drop_duplicates(['col_0']) # default keep='first'\n",
    "print(df_deduplicated)\n",
    "# keep\n",
    "# first: Drop duplicates except for the first occurrence.\n",
    "# last: Drop duplicates except for the last occurrence.\n",
    "# False: Drop all duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6.2.2 Replacing values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 按照字典的键值对，将所有需要被替换的值写到字典中，可以实现一次性对多项数据的替换。\n",
    "print(df)\n",
    "city_to_country = {'London': 'UK',\n",
    "                  'New York': 'US',\n",
    "                  'Shanghai': 'CN'}\n",
    "df_replaced = df.replace(city_to_country)\n",
    "print(df_replaced)\n",
    "\n",
    "         date      city  min_temp_C  max_temp_C\n",
    "0  2017-01-01    London           4          10\n",
    "1  2017-01-01  New York           5           8\n",
    "2  2017-01-01  Shanghai           5          15\n",
    "3  2017-01-02    London          -1           5\n",
    "4  2017-01-02  New York           3           4\n",
    "5  2017-01-02  Shanghai           8          15\n",
    "6  2017-01-03    London          -2           5\n",
    "7  2017-01-03  New York           4           6\n",
    "8  2017-01-03  Shanghai           7          14\n",
    "         date city  min_temp_C  max_temp_C\n",
    "0  2017-01-01   UK           4          10\n",
    "1  2017-01-01   US           5           8\n",
    "2  2017-01-01   CN           5          15\n",
    "3  2017-01-02   UK          -1           5\n",
    "4  2017-01-02   US           3           4\n",
    "5  2017-01-02   CN           8          15\n",
    "6  2017-01-03   UK          -2           5\n",
    "7  2017-01-03   US           4           6\n",
    "8  2017-01-03   CN           7          14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6.2.3 Renaming Index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Renaming column names\n",
    "\n",
    "# 对列名进行修改\n",
    "print(df_replaced)\n",
    "df_col_renamed = df_replaced.rename(columns={'city': 'country'})\n",
    "print(df_col_renamed)\n",
    "\n",
    "         date city  min_temp_C  max_temp_C\n",
    "0  2017-01-01   UK           4          10\n",
    "1  2017-01-01   US           5           8\n",
    "2  2017-01-01   CN           5          15\n",
    "3  2017-01-02   UK          -1           5\n",
    "4  2017-01-02   US           3           4\n",
    "5  2017-01-02   CN           8          15\n",
    "6  2017-01-03   UK          -2           5\n",
    "7  2017-01-03   US           4           6\n",
    "8  2017-01-03   CN           7          14\n",
    "         date country  min_temp_C  max_temp_C\n",
    "0  2017-01-01      UK           4          10\n",
    "1  2017-01-01      US           5           8\n",
    "2  2017-01-01      CN           5          15\n",
    "3  2017-01-02      UK          -1           5\n",
    "4  2017-01-02      US           3           4\n",
    "5  2017-01-02      CN           8          15\n",
    "6  2017-01-03      UK          -2           5\n",
    "7  2017-01-03      US           4           6\n",
    "8  2017-01-03      CN           7          14"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Renaming row indexes\n",
    "df_col_renamed = df_col_renamed.set_index('country')\n",
    "print(df_col_renamed)\n",
    "df_row_renamed = df_col_renamed.rename(index={'UK': 'United Kindom',\n",
    "                                              'US': 'United States',\n",
    "                                              'CN': 'China'})\n",
    "print(df_row_renamed)\n",
    "\n",
    "               date  min_temp_C  max_temp_C\n",
    "country                                    \n",
    "UK       2017-01-01           4          10\n",
    "US       2017-01-01           5           8\n",
    "CN       2017-01-01           5          15\n",
    "UK       2017-01-02          -1           5\n",
    "US       2017-01-02           3           4\n",
    "CN       2017-01-02           8          15\n",
    "UK       2017-01-03          -2           5\n",
    "US       2017-01-03           4           6\n",
    "CN       2017-01-03           7          14\n",
    "\n",
    "                     date  min_temp_C  max_temp_C\n",
    "country                                          \n",
    "United Kindom  2017-01-01           4          10\n",
    "United States  2017-01-01           5           8\n",
    "China          2017-01-01           5          15\n",
    "United Kindom  2017-01-02          -1           5\n",
    "United States  2017-01-02           3           4\n",
    "China          2017-01-02           8          15\n",
    "United Kindom  2017-01-03          -2           5\n",
    "United States  2017-01-03           4           6\n",
    "China          2017-01-03           7          14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6.2.4 Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(80, 90], (70, 80], (90, 100], (80, 90], (70, 80], ..., (0, 60], (80, 90], (70, 80], (80, 90], (80, 90]]\n",
      "Length: 12\n",
      "Categories (5, interval[int64]): [(0, 60] < (60, 70] < (70, 80] < (80, 90] < (90, 100]]\n",
      "(90, 100]    1\n",
      "(80, 90]     5\n",
      "(70, 80]     4\n",
      "(60, 70]     1\n",
      "(0, 60]      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specifying bin boundaries\n",
    "\n",
    "# bin取值的时候采用左开右闭的形式，即右边可以取到，左边取不到\n",
    "x = np.array([90, 80, 98, 85, 74, 62, 73, 5, 84, 74, 88, 85])\n",
    "binned = pd.cut(x, bins=[0, 60, 70, 80, 90, 100])\n",
    "print(binned)\n",
    "print(pd.value_counts(binned).sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(87.5, 98.0], (77.0, 87.5], (87.5, 98.0], (77.0, 87.5], (66.5, 77.0], ..., (55.958, 66.5], (77.0, 87.5], (66.5, 77.0], (87.5, 98.0], (77.0, 87.5]]\n",
      "Length: 12\n",
      "Categories (4, interval[float64]): [(55.958, 66.5] < (66.5, 77.0] < (77.0, 87.5] < (87.5, 98.0]]\n",
      "(87.5, 98.0]      3\n",
      "(77.0, 87.5]      4\n",
      "(66.5, 77.0]      3\n",
      "(55.958, 66.5]    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specifying number of equal-length bins\n",
    "\n",
    "# 按照从最小值到最大值，取4个区间\n",
    "x = np.array([90, 80, 98, 85, 74, 62, 73, 56, 84, 74, 88, 85])\n",
    "binned = pd.cut(x, bins=4)\n",
    "print(binned)\n",
    "print(pd.value_counts(binned).sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97.12, 98.0]      1\n",
      "(82.0, 97.12]      5\n",
      "(73.75, 82.0]      3\n",
      "(55.999, 73.75]    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specifying number of quantiles, same number of items in each bin\n",
    "\n",
    "# 具体指出计数的分位点，取值为其之间的区间，相当于前1%的为一个区间，1%到50%之间为一个区间。\n",
    "x = np.array([90, 80, 98, 85, 74, 62, 73, 56, 84, 74, 88, 85])\n",
    "binned = pd.qcut(x, q=[0, 0.25, 0.5, 0.99, 1])\n",
    "print(pd.value_counts(binned).sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F    1\n",
      "D    1\n",
      "C    4\n",
      "B    5\n",
      "A    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Adding labels for the resulting bins\n",
    "\n",
    "# 取值的同时，对取出的值进行贴标签\n",
    "x = np.array([90, 80, 98, 85, 74, 62, 73, 56, 84, 74, 88, 85])\n",
    "binned = pd.cut(x, bins=[0, 60, 70, 80, 90, 100], \n",
    "                labels=['F', 'D', 'C', 'B', 'A'])\n",
    "print(pd.value_counts(binned).sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 6.2.5 Dummy Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虚拟变量又称虚设变量、名义变量或哑变量，用以反映质的属性的一个人工变量,是量化了的质变量，通常取值为0或1。引入哑变量可使线形回归模型变得更复杂，但对问题描述更简明，一个方程能达到俩个方程的作用，而且接近现实。\n",
    "\n",
    "　　例如，反映文程度的虚拟变量可取为：1:本科学历；0：非本科学历\n",
    "\n",
    "　　一般地，在虚拟变量的设置中：基础类型、肯定类型取值为1；比较类型，否定类型取值为0。\n",
    "  \n",
    "更多的说明参见：http://wiki.mbalib.com/wiki/%E8%99%9A%E6%8B%9F%E5%8F%98%E9%87%8F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gender\n",
      "0      F\n",
      "1      M\n",
      "2      M\n",
      "3      F\n",
      "   F  M\n",
      "0  1  0\n",
      "1  0  1\n",
      "2  0  1\n",
      "3  1  0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'gender': ['F', 'M', 'M', 'F']\n",
    "})\n",
    "print(df)\n",
    "print(pd.get_dummies(df['gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gender\n",
      "0      F\n",
      "1      M\n",
      "2      M\n",
      "3      F\n",
      "   M\n",
      "0  0\n",
      "1  1\n",
      "2  1\n",
      "3  0\n"
     ]
    }
   ],
   "source": [
    "# Drop a column to avoid collinearity\n",
    "df = pd.DataFrame({\n",
    "    'gender': ['F', 'M', 'M', 'F']\n",
    "})\n",
    "print(df)\n",
    "print(pd.get_dummies(df['gender'], drop_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gender\n",
      "0      F\n",
      "1      M\n",
      "2      M\n",
      "3      F\n",
      "   gender_F  gender_M\n",
      "0         1         0\n",
      "1         0         1\n",
      "2         0         1\n",
      "3         1         0\n"
     ]
    }
   ],
   "source": [
    "# Add prefix\n",
    "# 引进虚变量的过程中加入前缀\n",
    "df = pd.DataFrame({\n",
    "    'gender': ['F', 'M', 'M', 'F']\n",
    "})\n",
    "print(df)\n",
    "print(pd.get_dummies(df['gender'], prefix='gender'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 7. String Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7.1 Vectorized String Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.1 Uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Banana\n",
      "2    Orange\n",
      "dtype: object\n",
      "0     APPLE\n",
      "1    BANANA\n",
      "2    ORANGE\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['Apple', 'Banana', 'Orange'])\n",
    "print(s)\n",
    "print(s.str.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.2 Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Banana\n",
      "2    Orange\n",
      "dtype: object\n",
      "0     APPLE\n",
      "1    BANANA\n",
      "2    ORANGE\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['Apple', 'Banana', 'Orange'])\n",
    "print(s)\n",
    "print(s.str.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.3 String Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Banana\n",
      "2    Orange\n",
      "dtype: object\n",
      "0    5\n",
      "1    6\n",
      "2    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['Apple', 'Banana', 'Orange'])\n",
    "print(s)\n",
    "print(s.str.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.4 Trimming Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'none', u'   left', u'right   ', u'   both   '], dtype='object')\n",
      "Index([u'none', u'left', u'right', u'both'], dtype='object')\n",
      "Index([u'none', u'left', u'right   ', u'both   '], dtype='object')\n",
      "Index([u'none', u'   left', u'right', u'   both'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "s = pd.Index(['none', '   left', 'right   ', '   both   '])\n",
    "print(s)\n",
    "# strip trims both sides\n",
    "print(s.str.strip())\n",
    "# lstrip trims left side\n",
    "print(s.str.lstrip())\n",
    "# rstrip trims right side\n",
    "print(s.str.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.5 Index of Found Substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        AAAA\n",
      "1    Bdfanana\n",
      "2      Orange\n",
      "dtype: object\n",
      "0   -1\n",
      "1    3\n",
      "2    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find\n",
    "# Returns lowest indexes in each strings # 返回找到的最小的位置值\n",
    "# Returns -1 on failure # 如果没有找到就返回-1\n",
    "\n",
    "# 查找某一个特定的值出现的次数\n",
    "s = pd.Series(['AAAA', 'Bdfanana', 'Orange'])\n",
    "print(s)\n",
    "print(s.str.find('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.6 Replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Apple\n",
      "1    Banana\n",
      "2    Orange\n",
      "dtype: object\n",
      "0     Apple\n",
      "1    B@n@n@\n",
      "2    Or@nge\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['Apple', 'Banana', 'Orange'])\n",
    "print(s)\n",
    "print(s.str.replace('a', '@')) # 识别过程中区分大小写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.7 Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a_b_c\n",
      "1      d_e\n",
      "dtype: object\n",
      "0    [a, b, c]\n",
      "1       [d, e]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['a_b_c', 'd_e']) # 对字符串进行分割\n",
    "print(s)\n",
    "print(s.str.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a_b_c\n",
      "1      d_e\n",
      "dtype: object\n",
      "   0  1     2\n",
      "0  a  b     c\n",
      "1  d  e  None\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(['a_b_c', 'd_e'])\n",
    "print(s)\n",
    "print(s.str.split('_', expand=True)) # Expanding into DataFrame 将拆分结果转化为数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.1.8 Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [a, b, c]\n",
      "1       [d, e]\n",
      "dtype: object\n",
      "0    a_b_c\n",
      "1      d_e\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([['a', 'b', 'c'], ['d', 'e']]) #对字符串进行合并\n",
    "print(s)\n",
    "print(s.str.join('_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 7.2 Vectorized String Method with Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于正则表达式的更多内容可以参见如下链接：\n",
    "\n",
    "https://docs.python.org/3/howto/regex.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.2.1 Counting Matched Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                1\n",
      "1               a2\n",
      "2              3b4\n",
      "3             c5d6\n",
      "4    22321b3dfsf23\n",
      "dtype: object\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    2\n",
      "4    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pattern = r'[a-z][0-9]'\n",
    "s = pd.Series(['1', 'a2', '3b4', 'c5d6', '22321b3dfsf23'])\n",
    "print(s)\n",
    "print(s.str.count(pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.2.2 Finding Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1      a2\n",
      "2     3b4\n",
      "3    c5d6\n",
      "dtype: object\n",
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Contains relies on re.search, and matches any part of the string\n",
    "# contain依赖于re模块的search方法，如果满足特定形式就可以，返回找到（True）\n",
    "pattern = r'[a-z][0-9]'\n",
    "s = pd.Series(['1', 'a2', '3b4', 'c5d6'])\n",
    "print(s)\n",
    "print(s.str.contains(pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1      a2\n",
      "2     3b4\n",
      "3    c5d6\n",
      "dtype: object\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Match relies on re.match, and matches only the beginning of the string\n",
    "# macth依赖于re模块的match方法，必须从开首字母就满足正则匹配的要求，否则返回False\n",
    "pattern = r'[a-z][0-9]'\n",
    "s = pd.Series(['1', 'a2', '3b4', 'c5d6'])\n",
    "print(s)\n",
    "print(s.str.match(pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1      a2\n",
      "2     3b4\n",
      "3    c5d6\n",
      "dtype: object\n",
      "0          []\n",
      "1        [a2]\n",
      "2        [b4]\n",
      "3    [c5, d6]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Finding all occurrences of pattern\n",
    "\n",
    "# 类似于re模块的findall，会将所有满足匹配要求的行返回\n",
    "pattern = r'[a-z][0-9]'\n",
    "s = pd.Series(['1', 'a2', '3b4', 'c5d6'])\n",
    "print(s)\n",
    "print(s.str.findall(pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7.2.3 Extracting Matched Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1      a2\n",
      "2     3b4\n",
      "3    c5d6\n",
      "4     1a1\n",
      "dtype: object\n",
      "  col_0 col_1\n",
      "0   NaN   NaN\n",
      "1     a     2\n",
      "2     b     4\n",
      "3     c     5\n",
      "4     a     1\n"
     ]
    }
   ],
   "source": [
    "# Extract groups from the first matched patterns\n",
    "\n",
    "# ?P<>为正则匹配中的分组命名，这里将第一组匹配结果命名为col_0, 第二组命名col_1\n",
    "pattern='(?P<col_0>[a-z])(?P<col_1>[0-9])'\n",
    "s = pd.Series(['1', 'a2', '3b4', 'c5d6', '1a1'])\n",
    "print(s)\n",
    "print(s.str.extract(pattern, expand=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1      a2\n",
      "2     3b4\n",
      "3    c5d6\n",
      "dtype: object\n",
      "        col_0 col_1\n",
      "  match            \n",
      "1 0         a     2\n",
      "2 0         b     4\n",
      "3 0         c     5\n",
      "  1         d     6\n"
     ]
    }
   ],
   "source": [
    "# Extract groups from all matched patterns\n",
    "\n",
    "# 匹配并返回所有符合要求的结果，而不是仅仅一次\n",
    "pattern='(?P<col_0>[a-z])(?P<col_1>[0-9])'\n",
    "s = pd.Series(['1', 'a2', '3b4', 'c5d6'])\n",
    "print(s)\n",
    "print(s.str.extractall(pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8. Group Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The \"group by\" process:\n",
    "1. Splitting the data into groups\n",
    "2. Applying a function to each group\n",
    "    2. Aggreation\n",
    "    3. Transformation\n",
    "    4. Filtration\n",
    "3. Combining the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 8.1 Splitting the Data into Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Grouping needs a mapping of labels to group names:\n",
    "For DataFrame, a string indicating a column name to be grouped by.\n",
    "A list of the same length as the selected axis.\n",
    "A dict providing a mapping from labels to group names.\n",
    "A function to be called on each of the axis lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1      1  foo  one\n",
      "1      2      2  bar  two\n",
      "2      3      1  foo  one\n",
      "3      4      2  bar  one\n",
      "bar\n",
      "   data1  data2 key1 key2\n",
      "1      2      2  bar  two\n",
      "3      4      2  bar  one\n",
      "foo\n",
      "   data1  data2 key1 key2\n",
      "0      1      1  foo  one\n",
      "2      3      1  foo  one\n"
     ]
    }
   ],
   "source": [
    "# Splitting by DataFrame column name(s)\n",
    "\n",
    "# 分组完以后得到的是两个分组\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [1, 2, 1, 2]})\n",
    "print(df)\n",
    "grouped = df.groupby('key1')\n",
    "for a, b in grouped:\n",
    "    print(a)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "('bar', 'one')\n",
      "   data1  data2 key1 key2\n",
      "3      4     40  bar  one\n",
      "('bar', 'two')\n",
      "   data1  data2 key1 key2\n",
      "1      2     20  bar  two\n",
      "('foo', 'one')\n",
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "2      3     30  foo  one\n"
     ]
    }
   ],
   "source": [
    "# Splitting by DataFrame column name(s)\n",
    "\n",
    "# 同时以多列进行筛选\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "grouped = df.groupby(['key1', 'key2'])\n",
    "for (key1, key2), group in grouped:\n",
    "    print(key1, key2)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40   ba  one\n",
      "group1\n",
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "2      3     30  foo  one\n",
      "group2\n",
      "   data1  data2 key1 key2\n",
      "1      2     20  bar  two\n",
      "3      4     40   ba  one\n"
     ]
    }
   ],
   "source": [
    "# Splitting by a list of the same length as the selected axis.\n",
    "# 按照行对数组进行分组，拥有相同命名的被自动分配到一起\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'ba'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "alist = ['group1', 'group2', 'group1', 'group2']\n",
    "grouped = df.groupby(alist)\n",
    "for key, group in grouped:\n",
    "    print(key)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "group1\n",
      "   data1  data2 key1 key2\n",
      "2      3     30  foo  one\n",
      "group2\n",
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "3      4     40  bar  one\n"
     ]
    }
   ],
   "source": [
    "# Splitting by a dict providing a mapping from labels to group names.\n",
    "# 按键值对进行分组，这里的键可以理解为index值，而值可以理解为对于不同组的命名，拥有相同命名的会自动被分到一起\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "adict = {0: 'group2', 1: 'group2', 2: 'group1', 3: 'group2'}\n",
    "grouped = df.groupby(adict)\n",
    "for key, group in grouped:\n",
    "    print(key)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "0\n",
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "3      4     40  bar  one\n",
      "1\n",
      "   data1  data2 key1 key2\n",
      "1      2     20  bar  two\n",
      "2\n",
      "   data1  data2 key1 key2\n",
      "2      3     30  foo  one\n"
     ]
    }
   ],
   "source": [
    "# Splitting by a function to be called on each of the axis lables.\n",
    "# Return values will be used as group names\n",
    "\n",
    "# np.remainder是返回两个数相除以后的余数\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "afunc = lambda x: np.mod(x, 3)\n",
    "grouped = df.groupby(afunc)\n",
    "for key, group in grouped:\n",
    "    print(key)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "关于更多的numpy数学运算，参见如下连接\n",
    "\n",
    "http://www.mamicode.com/info-detail-1794242.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "('bar', 'one')\n",
      "   data1  data2 key1 key2\n",
      "3      4     40  bar  one\n",
      "('bar', 'two')\n",
      "   data1  data2 key1 key2\n",
      "1      2     20  bar  two\n",
      "('foo', 'one')\n",
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "2      3     30  foo  one\n",
      "   data1  data2 key1 key2\n",
      "3      4     40  bar  one\n"
     ]
    }
   ],
   "source": [
    "# Selecting a group\n",
    "# 取出特定的组只需要使用get_group以及写出组名即可\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "grouped = df.groupby(['key1', 'key2'])\n",
    "for (key1, key2), group in grouped:\n",
    "    print(key1, key2)\n",
    "    print(group)\n",
    "print(grouped.get_group(('bar', 'one')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 8.2 Applying a Function to Each Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 8.2.1 Aggregation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Aggregation computes a summary statistic about each group.\n",
    "Aggregation reduces the dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "      data1  data2\n",
      "key1              \n",
      "bar       3     30\n",
      "foo       2     20\n"
     ]
    }
   ],
   "source": [
    "# Aggregation via GroupBy object method\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  foo  one\n",
      "key1\n",
      "bar    1\n",
      "foo    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Aggregation via GroupBy object method\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'foo'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "key1               bar        foo\n",
      "data1 count   2.000000   2.000000\n",
      "      mean    3.000000   2.000000\n",
      "      std     1.414214   1.414214\n",
      "      min     2.000000   1.000000\n",
      "      25%     2.500000   1.500000\n",
      "      50%     3.000000   2.000000\n",
      "      75%     3.500000   2.500000\n",
      "      max     4.000000   3.000000\n",
      "data2 count   2.000000   2.000000\n",
      "      mean   30.000000  20.000000\n",
      "      std    14.142136  14.142136\n",
      "      min    20.000000  10.000000\n",
      "      25%    25.000000  15.000000\n",
      "      50%    30.000000  20.000000\n",
      "      75%    35.000000  25.000000\n",
      "      max    40.000000  30.000000\n"
     ]
    }
   ],
   "source": [
    "# Aggregation via GroupBy object method\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1').describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "      data1  data2\n",
      "key1              \n",
      "bar       3     30\n",
      "foo       2     20\n"
     ]
    }
   ],
   "source": [
    "# Aggregation via the aggregate method\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1').agg(np.mean)) \n",
    "# 如果不指定level的话是按照列来组，指定level是按照行来组合排序\n",
    "# Group names will be the new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1  key2\n",
      "0      1     10  foo     1\n",
      "1      2     20  bar     2\n",
      "2      3     30  foo     3\n",
      "3      4     40  bar     4\n",
      "      data1  data2  key2\n",
      "key1                    \n",
      "bar       3     30     3\n",
      "foo       2     20     2\n"
     ]
    }
   ],
   "source": [
    "# Aggregation via the aggregate method\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': [1, 2, 3, 4],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1').agg(np.mean))\n",
    "# Group names will NOT be the new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "  key1  data1  data2\n",
      "0  bar      3     30\n",
      "1  foo      2     20\n"
     ]
    }
   ],
   "source": [
    "# Aggregation via the aggregate method\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1', as_index=False).agg(np.mean)) \n",
    "# Group names will NOT be the new index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 8.2.2 Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  foo  one\n",
      "   data1  data2 key2\n",
      "0      4     40  one\n",
      "1      2     20  two\n",
      "2      4     40  one\n",
      "3      4     40  one\n"
     ]
    }
   ],
   "source": [
    "# 用分组以后的值，替换原有的值\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'foo'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1').transform(np.max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 8.2.3 Filtration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Filtration discard some groups according to a group-wise computation that returns True or False.\n",
    "Filtration returns a subset of the original object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "   data1  data2 key1 key2\n",
      "1      2     20  bar  two\n",
      "3      4     40  bar  one\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "print(df.groupby('key1').filter(lambda x: x['data1'].mean() > 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 8.3 Pivot Tables and Cross Tabulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 8.3.1 Pivot Tables"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pivot_table pivots with aggregation of numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "key2  one  two\n",
      "key1          \n",
      "bar   4.0  2.0\n",
      "foo   2.0  NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "df_pivoted = df.pivot_table(values='data1', \n",
    "                            index='key1', \n",
    "                            columns='key2', \n",
    "                            aggfunc=np.mean)\n",
    "print(df_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "         data1                data2            \n",
      "key2       one  two  All        one   two   All\n",
      "key1                                           \n",
      "bar   4.000000  2.0  3.0  40.000000  20.0  30.0\n",
      "foo   2.000000  NaN  2.0  20.000000   NaN  20.0\n",
      "All   2.666667  2.0  2.5  26.666667  20.0  25.0\n"
     ]
    }
   ],
   "source": [
    "# Add margins\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "df_pivoted = df.pivot_table(values=['data1', 'data2'],\n",
    "                            index='key1', \n",
    "                            columns='key2', \n",
    "                            aggfunc=np.mean, \n",
    "                            margins=True)\n",
    "print(df_pivoted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "key2  one  two\n",
      "key1          \n",
      "bar   4.0  2.0\n",
      "foo   2.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# Add margins\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "df_pivoted = df.pivot_table(values='data1', \n",
    "                            index='key1', \n",
    "                            columns='key2', \n",
    "                            aggfunc=np.mean, \n",
    "                            margins=False)\n",
    "print(df_pivoted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 8.3.2 Cross Tabulations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "crosstab computes a cross-tabulation of two factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data1  data2 key1 key2\n",
      "0      1     10  foo  one\n",
      "1      2     20  bar  two\n",
      "2      3     30  foo  one\n",
      "3      4     40  bar  one\n",
      "keyl  1  2  3  4\n",
      "key1            \n",
      "bar   0  1  0  1\n",
      "foo   1  0  1  0\n"
     ]
    }
   ],
   "source": [
    "# 交叉表查询，类似于数据库应用的如下语句\n",
    "# (select 表1.成员姓名 from 表2 b where 表1.成员1id=表2.成员id) as 成员1id,\n",
    "\n",
    "df = pd.DataFrame({'key1': ['foo', 'bar', 'foo', 'bar'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "df2 = pd.DataFrame({'keyl': ['1', '2', '3', '4'],\n",
    "                   'key2': ['one', 'two', 'one', 'one'],\n",
    "                   'data1': [1, 2, 3, 4],\n",
    "                   'data2': [10, 20, 30, 40]})\n",
    "print(df)\n",
    "df_crosstab = pd.crosstab(index=df['key1'], columns=df2['keyl'])\n",
    "print(df_crosstab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
